{
 "metadata": {
  "kernelspec": {
   "display_name": "sp39",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  },
  "lastEditStatus": {
   "notebookId": "hhddciwqssntpdryemcm",
   "authorId": "1126630220347",
   "authorName": "JPARRADO",
   "authorEmail": "jorge.parrado@snowflake.com",
   "sessionId": "f47762da-10e9-476a-9d16-8781b19992a4",
   "lastEditTime": 1746585580553
  }
 },
 "nbformat_minor": 5,
 "nbformat": 4,
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3a5d316b-af86-4f60-93f4-8ed386bf5ce5",
   "metadata": {
    "name": "cell2",
    "collapsed": false
   },
   "source": "# Primeros pasos con la Observabilidad de ML en Snowflake\n\n## Resumen\n\nMLOps es una funci√≥n central de la ingenier√≠a de ML y se enfoca en agilizar el proceso de llevar modelos de machine learning a producci√≥n, y luego mantenerlos y monitorearlos de manera efectiva. A diferencia del software tradicional, los modelos de machine learning pueden cambiar su comportamiento con el tiempo debido a varios factores, incluyendo la deriva de entrada (input drift), suposiciones obsoletas del entrenamiento del modelo, problemas en los pipelines de datos (data pipelines), y desaf√≠os est√°ndar como los entornos de hardware/software y el tr√°fico. Estos factores pueden llevar a una disminuci√≥n en el rendimiento del modelo y a un comportamiento inesperado que necesita ser monitoreado muy de cerca.\n\nSnowflake ML proporciona a las organizaciones un conjunto integrado de capacidades para machine learning de extremo a extremo en una √∫nica plataforma sobre datos gobernados. El comportamiento del modelo puede cambiar con el tiempo debido a la deriva de entrada (input drift), suposiciones de entrenamiento obsoletas, y problemas en los pipelines de datos (data pipelines), as√≠ como los factores habituales, incluyendo cambios en el hardware y software subyacentes y la naturaleza fluida del tr√°fico. La caracter√≠stica de Observabilidad de ML de Snowflake te permite rastrear la calidad de los modelos en producci√≥n que has desplegado a trav√©s del Snowflake Model Registry a trav√©s de m√∫ltiples dimensiones, como rendimiento, deriva y volumen.\n\nEste repositorio contiene un notebook que te gu√≠a a trav√©s de la construcci√≥n, despliegue y monitoreo de un modelo de predicci√≥n de abandono de clientes (customer churn prediction) en Snowflake.\n\n[Fuente](https://quickstarts.snowflake.com/guide/getting-started-with-ml-observability-in-snowflake/index.html#0)\n"
  },
  {
   "cell_type": "markdown",
   "id": "5b4d192a-ebd2-41f7-a992-55e5e40c68bc",
   "metadata": {
    "collapsed": false,
    "name": "Title",
    "resultHeight": 943
   },
   "source": "![](https://www.snowflake.com/wp-content/themes/snowflake/assets/img/brand-guidelines/logo-sno-blue-example.svg)\n\n# Construye, Despliega y Monitoriza tu Modelo en Snowflake\n\nEn esta laboratorio veremos c√≥mo es un ciclo de vida completo de un modelo en Snowflake.\nUtilizaremos las siguientes funcionalidades de Snowflake:\n\n* Snowflake ML Python SDK\n* Registro de Modelos\n* Observabilidad de ML\n* Alertas\n* Monitorizaci√≥n de Deriva\n\n![](https://drive.google.com/file/d/1jWryVEAjyetHMRgTTMo_bnx_BZRdeNuC/view?usp=sharing)\n\n>**Caso de uso:** Su empresa est√° teniendo problamas con la p√©rdida de clientes a manos de la competencia. Deseas comprender la probabilidad de que cada uno de los clientes abandone, con el objetivo, de tomar las medidas necesarias para los usuarios con alta probabilidad de abandono. Con el tiempo, se observa una nueva tendencia en la p√©rdida de clientes que debe abordarse de inmediato para obtener una ventaja competitiva. La instituci√≥n financiera aprovecha el panel de Observabilidad de ML para ver las m√©tricas y los factores de precisi√≥n. Puede tomar medidas proactivas para reentrenar el modelo y tambi√©n comparar diferentes versiones del modelo monitorizando el rendimiento del modelo.\n\n### **Caracter√≠sticas**\n\n* **CREDITSCORE:** Puntuaci√≥n de cr√©dito del cliente basada en su comportamiento y gesti√≥n crediticia hist√≥rica\n* **GEOGRAPHY:** Pa√≠s de residencia\n* **GENDER:** G√©nero del cliente\n* **AGE:** Edad del cliente\n* **TENURE:** Duraci√≥n en a√±os que han sido cliente\n* **BALANCE:** Saldo actual de su cuenta bancaria\n* **NUMOFPRODUCTS:** N√∫mero de productos comprados al banco\n* **HASCRCARD:** ¬øTiene el cliente tarjeta de cr√©dito? - 1 si la tiene, 0 si no\n* **ISACTIVEMEMBER:** ¬øHa utilizado el cliente su cuenta bancaria en los √∫ltimos 3 meses? - 1 si lo hizo, 0 si no lo hizo\n* **ESTIMATEDSALARY:** Salario estimado del cliente\n* **DEBTTOINCOME:** Relaci√≥n deuda-ingresos\n\n### **Modelo**\n\nConstruiremos un modelo de clasificaci√≥n utilizando el framework XGBoost con la API de ML de Snowflake y registraremos el modelo en el registro. A lo largo del proceso, crearemos monitores de modelo y veremos el rendimiento del modelo en el panel de Snowsight."
  },
  {
   "cell_type": "markdown",
   "id": "6d6cd626-098f-4e67-82f4-83a9b11dc50b",
   "metadata": {
    "name": "cell1",
    "collapsed": false
   },
   "source": "#### Agrega los siguientes paquetes: `snowflake-ml-python`,`snowflake-snowpark-python`"
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "3775908f-ca36-4846-8f38-5adca39217f2",
   "metadata": {
    "codeCollapsed": false,
    "collapsed": false,
    "language": "python",
    "name": "importheaders",
    "resultHeight": 54
   },
   "outputs": [],
   "source": "# Import python packages\nimport streamlit as st\nimport pandas as pd\n\nfrom snowflake.snowpark.context import get_active_session\nsession = get_active_session()\nfrom datetime import datetime, timedelta\nfrom snowflake.ml.registry import Registry\nimport joblib\nfrom snowflake.ml.modeling.pipeline import Pipeline\nimport snowflake.ml.modeling.preprocessing as pp\nfrom snowflake.ml.modeling.xgboost import XGBClassifier\nfrom snowflake.snowpark.types import StringType, IntegerType\nimport snowflake.snowpark.functions as F\nfrom snowflake.snowpark.functions import col, current_date, dateadd, random, floor,current_date, datediff\nimport warnings\nwarnings.filterwarnings('ignore')\n\nsession.query_tag = {\"origin\":\"sf_sit-is\", \"name\":\"mlops_customerchurn\", \"version\":{\"major\":1, \"minor\":0}}\n\nimport snowflake.snowpark.functions as F\nfrom IPython.display import Markdown, display\n\nsolution_prefix = session.get_current_warehouse()\nsolution_prefix"
  },
  {
   "cell_type": "markdown",
   "id": "3e51a542-d06f-42fc-ad28-2f408f940b04",
   "metadata": {
    "collapsed": false,
    "name": "load_data",
    "resultHeight": 46
   },
   "source": "### Cargar datos sint√©ticos del data_stage a una tabla de Snowflake usando un comando COPY INTO."
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "a8a2ccd3-075f-4a1e-9ab0-00e248cc9e4e",
   "metadata": {
    "codeCollapsed": false,
    "collapsed": false,
    "language": "sql",
    "name": "initial_customer_dataset",
    "resultHeight": 111
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total exited customers: 1714 (Target: ~2000)\n",
      "   CustomerId  Surname  CreditScore Geography  Gender  Age  Tenure    Balance  \\\n",
      "0           1    Johns          402    France    Male   55       9   91944.03   \n",
      "1           2  Schultz          735     Spain    Male   59       8  126536.56   \n",
      "2           3    Jones          570     Spain    Male   54       7  191357.66   \n",
      "3           4    Baker          406    France  Female   73       3  125263.00   \n",
      "4           5  Aguirre          371     Spain    Male   88       9  195626.75   \n",
      "\n",
      "   NumOfProducts  HasCrCard  IsActiveMember  EstimatedSalary  Exited  \\\n",
      "0              1          1               1         36899.18       0   \n",
      "1              2          0               0         33120.74       0   \n",
      "2              2          1               1         34751.09       1   \n",
      "3              4          0               0        169844.77       0   \n",
      "4              4          0               1         13787.72       0   \n",
      "\n",
      "  TransactionTimestamp  debttoincome  \n",
      "0  2022-01-09 14:08:54            23  \n",
      "1  2022-04-19 06:29:13            80  \n",
      "2  2022-07-11 11:43:59            29  \n",
      "3  2022-12-03 05:38:57            24  \n",
      "4  2022-10-30 09:17:13            80  \n"
     ]
    }
   ],
   "source": [
    "-- Create csv format\n",
    "CREATE FILE FORMAT IF NOT EXISTS CSVFORMAT \n",
    "    SKIP_HEADER = 1 \n",
    "    TYPE = 'CSV';\n",
    "    \n",
    "CREATE OR REPLACE STAGE data_stage\n",
    "    FILE_FORMAT = (TYPE = 'CSV') \n",
    "    URL = 's3://sfquickstarts/sfguide_getting_started_with_ml_observability_in_snowflake/mlops_customerchurn.csv';\n",
    "    \n",
    "-- Inspect content of stage\n",
    "LS @data_stage;\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5283d28-3f4b-4247-93c3-43dc4e305315",
   "metadata": {
    "collapsed": false,
    "name": "read_csv_file",
    "resultHeight": 46
   },
   "source": "### Leer un archivo CSV usando Snowpark desde un stage en Snowflake a un DataFrame."
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "a349023c-8855-4b60-8bdd-35ec51c48141",
   "metadata": {
    "codeCollapsed": false,
    "collapsed": false,
    "language": "python",
    "name": "CUSTOMERS_DATA",
    "resultHeight": 0
   },
   "outputs": [],
   "source": [
    "spdf = session.read.options({\"field_delimiter\": \",\",\n",
    "                                    \"field_optionally_enclosed_by\": '\"',\n",
    "                                    \"infer_schema\": True,\n",
    "                                    \"parse_header\": True}).csv(\"@data_stage\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "id": "cb77670b-0bfb-4824-8b80-b12a0948b8a4",
   "metadata": {
    "language": "python",
    "name": "cast",
    "collapsed": false
   },
   "outputs": [],
   "source": "from snowflake.snowpark.types import DecimalType, FloatType, DoubleType\n\n# Get schema of the DataFrame\nschema = spdf.schema.fields\n\n# Identify columns that are of type NUMBER (DecimalType)\nnum_columns = [col.name for col in schema if isinstance(col.datatype, DecimalType)]\n\n# Convert columns to FLOAT\nfor col in num_columns:\n    spdf = spdf.with_column(col, spdf[col].cast(DoubleType()))\n\n",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "7ca65646-6250-41ec-bdae-277bc86e7b44",
   "metadata": {
    "language": "python",
    "name": "date_advance",
    "collapsed": false
   },
   "outputs": [],
   "source": "from snowflake.snowpark import Session\nfrom snowflake.snowpark.functions import col, current_date, dateadd, to_date,lit\n\n# Step 1: Get today's date\ntodays_date = datetime.now()\n\nlatest_date = max(spdf.select('TRANSACTIONTIMESTAMP').collect())[0]\n\n# Step 3: Calculate the difference in days\ndiff_days = (todays_date - latest_date).days - 1\n\ndf = spdf.with_column(\n    \"TRANSACTIONTIMESTAMP\", \n    dateadd(\"day\", lit(diff_days), col(\"TRANSACTIONTIMESTAMP\"))\n)\n\n\ndf = df.with_column(\n    \"CREDITSCORE\", col(\"CREDITSCORE\").cast(\"float\")\n)\ndf = df.with_column(\n    \"PREDICTED_CHURN\", F.lit(9999)\n)\ndf.show()\n\ndf.write.mode(\"overwrite\").save_as_table(\"CUSTOMERS\")\n",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "b4b2b17b-ba3b-4eb0-b302-585f066f87ab",
   "metadata": {
    "codeCollapsed": false,
    "collapsed": false,
    "language": "python",
    "name": "remove_rownum",
    "resultHeight": 350
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "|\"CUSTOMERID\"  |\"CREDITSCORE\"  |\"GEOGRAPHY\"  |\"GENDER\"  |\"AGE\"  |\"TENURE\"  |\"BALANCE\"  |\"NUMOFPRODUCTS\"  |\"HASCRCARD\"  |\"ISACTIVEMEMBER\"  |\"ESTIMATEDSALARY\"  |\"EXITED\"  |\"TRANSACTIONTIMESTAMP\"  |\"DEBTTOINCOME\"  |\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "|1             |402            |France       |Male      |55     |9         |91944.03   |1                |1            |1                 |36899.18           |0         |2022-01-09 14:08:54     |23              |\n",
      "|2             |735            |Spain        |Male      |59     |8         |126536.56  |2                |0            |0                 |33120.74           |0         |2022-04-19 06:29:13     |80              |\n",
      "|3             |570            |Spain        |Male      |54     |7         |191357.66  |2                |1            |1                 |34751.09           |1         |2022-07-11 11:43:59     |29              |\n",
      "|4             |406            |France       |Female    |73     |3         |125263.0   |4                |0            |0                 |169844.77          |0         |2022-12-03 05:38:57     |24              |\n",
      "|5             |371            |Spain        |Male      |88     |9         |195626.75  |4                |0            |1                 |13787.72           |0         |2022-10-30 09:17:13     |80              |\n",
      "|6             |320            |Germany      |Male      |72     |7         |28858.19   |3                |1            |0                 |48456.88           |0         |2023-11-26 06:10:34     |95              |\n",
      "|7             |421            |Spain        |Male      |71     |6         |15990.69   |3                |1            |0                 |191619.44          |1         |2022-10-02 08:53:11     |49              |\n",
      "|8             |766            |Spain        |Male      |39     |4         |39715.24   |1                |0            |1                 |22544.05           |0         |2022-01-17 10:34:53     |76              |\n",
      "|9             |514            |Spain        |Male      |44     |6         |193003.03  |3                |1            |1                 |16901.08           |0         |2022-01-15 01:31:26     |52              |\n",
      "|10            |630            |France       |Female    |64     |6         |189832.56  |3                |1            |1                 |83592.57           |0         |2023-12-09 06:53:42     |56              |\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spdf= df.drop('ROWNUMBER')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af5f72cd-5892-4656-ae23-3db6ffb1cd8e",
   "metadata": {
    "collapsed": false,
    "name": "preprocessing",
    "resultHeight": 66
   },
   "source": "#### Define un pipeline de preprocesamiento usando Pipeline con dos pasos: Ordinal Encoding (Codificaci√≥n Ordinal) para columnas categ√≥ricas y Escalado Min-Max para columnas num√©ricas. Luego divide los datos en conjuntos de entrenamiento y prueba, aplica los pasos de preprocesamiento a los datos de entrenamiento y guarda el pipeline como un archivo joblib (preprocessing_pipeline.joblib)."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a92413c3-0dea-4d98-a70a-0c77c72b0397",
   "metadata": {
    "codeCollapsed": false,
    "collapsed": false,
    "language": "python",
    "name": "preprocessing_pipeline_",
    "resultHeight": 287
   },
   "outputs": [],
   "source": "num_cols = ['ESTIMATEDSALARY', 'BALANCE', 'CREDITSCORE','AGE','TENURE','DEBTTOINCOME']\noutput_cols=['EstimatedSalary_SS', 'Balance_SS', 'CreditScore_SS','Age_SS','Tenure_SS','debttoincome_SS']\n\ncat_cols = ['HasCrCard', 'IsActiveMember', 'Geography','Gender', 'NumOfProducts']\nstring_columns = ['GEOGRAPHY', 'GENDER']\nstring_columns_oe = ['GEOGRAPHY_oe', 'GENDER_oe']\npreprocessing_pipeline = Pipeline(\n    steps=[\n            (\n                \"OE\",\n                pp.OrdinalEncoder(\n                    input_cols=string_columns,\n                    output_cols=string_columns_oe,\n                    drop_input_cols= False,\n                )\n                \n            ),\n            (\n                \"MMS\",\n                pp.MinMaxScaler(\n                    clip=True,\n                    input_cols=num_cols,\n                    output_cols=output_cols,\n                    drop_input_cols= False,\n                )\n            )\n    ]\n)\n\nPIPELINE_FILE = '/tmp/preprocessing_pipeline.joblib'\njoblib.dump(preprocessing_pipeline, PIPELINE_FILE) # We are just pickling it locally first\ntraining, testing = spdf.random_split(weights=[0.8, 0.2], seed=111)\ntraining_spdf = preprocessing_pipeline.fit(training).transform(training)\ntesting_spdf=preprocessing_pipeline.fit(testing).transform(testing)"
  },
  {
   "cell_type": "markdown",
   "id": "b5deeba5-4197-4a01-b93a-c797cbe13925",
   "metadata": {
    "collapsed": false,
    "name": "save_pipeline",
    "resultHeight": 47
   },
   "source": "#### Almacenar el archivo del pipeline en un stage"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "209b6772-3e92-49c1-a969-6f8a03ba7c8a",
   "metadata": {
    "codeCollapsed": false,
    "collapsed": false,
    "language": "python",
    "name": "ml_stage",
    "resultHeight": 354
   },
   "outputs": [],
   "source": [
    "session.sql(\"CREATE or replace stage ML_STAGE\").collect()\n",
    "session.file.put(PIPELINE_FILE, \"@ML_STAGE\", overwrite=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff15b984-9294-4e35-a76e-1e6210653ed9",
   "metadata": {
    "codeCollapsed": false,
    "collapsed": false,
    "language": "sql",
    "name": "view_stage",
    "resultHeight": 111
   },
   "outputs": [],
   "source": [
    "ls @ML_STAGE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a3bc115-40c0-4012-a5f5-c0a92b28e0fa",
   "metadata": {
    "collapsed": false,
    "name": "build_model",
    "resultHeight": 60
   },
   "source": "## Construir el modelo XGBClassifier y entrenarlo usando los datos de entrenamiento"
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "7af4a413-9d63-497e-a7a3-237553a363e1",
   "metadata": {
    "codeCollapsed": false,
    "collapsed": false,
    "language": "python",
    "name": "DEMO____initial_training",
    "resultHeight": 671
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<snowflake.snowpark.dataframe.DataFrame at 0x33cc21a60>"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": "num_cols = ['EstimatedSalary', 'Balance', 'CreditScore','Age','Tenure','debttoincome']\n\ncat_cols = ['HasCrCard', 'IsActiveMember', 'GEOGRAPHY','GENDER', 'NumOfProducts']\nTarget = [\"EXITED\"]\n\nfeature_names_input = [c for c in training_spdf.columns if c not in [\"EXITED\", \"TRANSACTIONTIMESTAMP\", \"CUSTOMERID\",\"ESTIMATEDSALARY\", \"BALANCE\", \"CREDITSCORE\",\"AGE\",\"TENURE\",\"DEBTTOINCOME\",\"GEOGRAPHY\",\"GENDER\",\"PREDICTED_CHURN\"]]\n\n\ntraining_spdf = training_spdf.with_column(\n    \"CREDITSCORE_SS\", col(\"CREDITSCORE_SS\").cast(\"float\")\n)\noutput_label = [\"PREDICTED_CHURN\"]\n# Initialize a XGBClassifier object with input, label, and output column names\nmodel = XGBClassifier(\n    input_cols=feature_names_input,\n    label_cols=Target,\n    output_cols=output_label\n    \n)\n\n# Train the classifier model using the training set\n_ = model.fit(training_spdf)\n\n"
  },
  {
   "cell_type": "markdown",
   "id": "cc86a6fb-7dba-4ba0-91b7-a0428301b3f2",
   "metadata": {
    "collapsed": false,
    "name": "init_registry",
    "resultHeight": 46
   },
   "source": "### Inicializar el Snowflake Model Registry\n\nRegistrar y gestionar el modelo de aprendizaje autom√°tico entrenado en Snowflake.\n\nObserva que task=type_hints.Task.TABULAR_BINARY_CLASSIFICATION: Especifica que esta es una tarea de clasificaci√≥n binaria (predecir el churn: Yes/No)."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "063b1cba-2e57-4508-9601-9955ac7a830e",
   "metadata": {
    "codeCollapsed": false,
    "collapsed": false,
    "language": "python",
    "name": "DEMO____log_model",
    "resultHeight": 111
   },
   "outputs": [],
   "source": "from snowflake.ml.registry import Registry\nfrom snowflake.ml.model import type_hints\n\nreg = Registry(session=session)\n\nMODEL_NAME = \"QS_CustomerChurn_classifier\"\nMODEL_VERSION = \"v1\"\n\nmv = reg.log_model(model,\n                   model_name=MODEL_NAME,\n                   version_name=MODEL_VERSION,\n                   options={'relax_version': True},\n                   task=type_hints.Task.TABULAR_BINARY_CLASSIFICATION)\nreg.show_models()\n"
  },
  {
   "cell_type": "markdown",
   "id": "a93bde85-0531-4ec5-b0ac-6b3baf7502fd",
   "metadata": {
    "collapsed": false,
    "name": "inference_fn",
    "resultHeight": 60
   },
   "source": "## Inferencia Continua\nLa funci√≥n de inferencia realiza predicciones utilizando un modelo preentranado de aprendizaje autom√°tico dentro de Snowflake. Esta funci√≥n utiliza el pipeline de preprocesamiento creado anteriormente para asegurar que los datos se transformen de manera consistente.\n‚úÖ Ejecuta predicciones utilizando una versi√≥n registrada del modelo.\n‚úÖ Actualiza las predicciones directamente en la tabla de Snowflake.\n‚úÖ Maneja eficientemente la inferencia en batch con actualizaciones SQL."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4709bd3d-7c4d-4bc3-aa99-ba3ea627ec31",
   "metadata": {
    "codeCollapsed": false,
    "collapsed": false,
    "language": "python",
    "name": "inference_utils",
    "resultHeight": 432
   },
   "outputs": [],
   "source": "from snowflake.ml.modeling.pipeline import Pipeline\nimport snowflake.ml.modeling.preprocessing as pp\nimport snowflake.snowpark.functions as F\n\ndef inference(table_name, modelname, modelversion) -> str:\n    reg = Registry(session=session)\n    m = reg.get_model(modelname)\n    mv = m.version(modelversion)\n    \n    # Load preprocessing pipeline from a file\n    session.file.get('@ML_STAGE/preprocessing_pipeline.joblib.gz', '/tmp')\n    pipeline_file = '/tmp/preprocessing_pipeline.joblib.gz'\n    \n    \n    preprocessing_pipeline = joblib.load(pipeline_file)\n    \n    df = session.table(table_name)\n    \n    # Apply preprocessing\n    testing_spdf = preprocessing_pipeline.fit(df).transform(df)\n    testing_spdf = testing_spdf.with_column(\n    \"CREDITSCORE_SS\", col(\"CREDITSCORE_SS\").cast(\"float\")\n)\n    # Perform prediction\n    results = mv.run(testing_spdf, function_name=\"predict\")\n    results =results.drop(\"CREDITSCORE_SS\", \"BALANCE_SS\", \"DEBTTOINCOME_SS\", \"TENURE_SS\", \"AGE_SS\", \"ESTIMATEDSALARY_SS\", \"GENDER_OE\", \"GEOGRAPHY_OE\")\n    #results.write.save_as_table(\"customer_churn\", mode=\"overwrite\")\n    results.create_or_replace_temp_view(\"results_temp\")\n    update_statement = f\"\"\"\n    UPDATE {table_name} t\n    SET PREDICTED_CHURN = r.PREDICTED_CHURN\n    FROM results_temp r\n    WHERE t.CUSTOMERID = r.CUSTOMERID\n    AND t.TRANSACTIONTIMESTAMP=r.TRANSACTIONTIMESTAMP;\n\"\"\"\n\n    # Execute the merge statement\n    session.sql(update_statement).collect()\n        \n    return \"Success\"\n"
  },
  {
   "cell_type": "markdown",
   "id": "12894ad5-c3a5-411d-bea7-7037fc9521d1",
   "metadata": {
    "name": "mkpredict1",
    "collapsed": false
   },
   "source": "Ejecuta el modelo entrenado sobre el DataFrame testing_spdf usando mv.run(). function_name=\"predict\" especifica que la funci√≥n a utilizar para la inferencia es \"predict\". La salida es un DataFrame que contiene las predicciones."
  },
  {
   "cell_type": "code",
   "id": "c3a4955a-9eda-4eb9-99eb-9156b526998a",
   "metadata": {
    "language": "python",
    "name": "inference_results",
    "collapsed": false
   },
   "outputs": [],
   "source": "testing_spdf = testing_spdf.with_column(\n    \"CREDITSCORE_SS\", col(\"CREDITSCORE_SS\").cast(\"float\")\n)\n# Perform prediction\nresults = mv.run(testing_spdf, function_name=\"predict\")\nresults",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "ccb54964-9adb-416d-898f-4e61a169bca2",
   "metadata": {
    "name": "SIMULATION",
    "collapsed": false
   },
   "source": "## DATA DRIFT (DERIVA DE DATOS) Y OBSERVABILIDAD EN EL PANEL DE OBSERVABILIDAD DE ML\n"
  },
  {
   "cell_type": "markdown",
   "id": "cdcea649-de3b-4859-81fb-338d5d9fc007",
   "metadata": {
    "name": "mkdrift",
    "collapsed": false
   },
   "source": "Ahora veamos c√≥mo se puede monitorizar una deriva de datos y c√≥mo una acci√≥n proactiva podr√≠a ayudar a la firma financiera a prevenir el abandono de clientes."
  },
  {
   "cell_type": "code",
   "id": "813f4936-3811-4ecf-b737-e33fbca0afa0",
   "metadata": {
    "language": "sql",
    "name": "read_drift_data",
    "collapsed": false
   },
   "outputs": [],
   "source": "-- Create csv format\nCREATE FILE FORMAT IF NOT EXISTS CSVFORMAT \n    SKIP_HEADER = 1 \n    TYPE = 'CSV';\n    \nCREATE OR REPLACE STAGE data_stage\n    FILE_FORMAT = (TYPE = 'CSV') \n    URL = 's3://sfquickstarts/sfguide_getting_started_with_ml_observability_in_snowflake/CUSTOMERS_DRIFTED.csv';\n    \n-- Inspect content of stage\nLS @data_stage;\n\n\n",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "1841cf81-4e9c-4929-bc9e-89a9af3c9d3a",
   "metadata": {
    "name": "mkcustdrift",
    "collapsed": false
   },
   "source": "Los datos en el archivo CUSTOMERS_DRIFTED contienen nuevas tendencias de clientes que llevan a una baja precisi√≥n de la inferencia usando la versi√≥n v1 del modelo."
  },
  {
   "cell_type": "code",
   "id": "71246d5a-ad5f-4804-98c9-d423047f9bd0",
   "metadata": {
    "language": "python",
    "name": "datatype_Cast",
    "collapsed": false
   },
   "outputs": [],
   "source": "spdf = session.read.options({\"field_delimiter\": \",\",\n                                    \"field_optionally_enclosed_by\": '\"',\n                                    \"infer_schema\": True,\n                                    \"parse_header\": True}).csv(\"@data_stage\")\n\nfrom snowflake.snowpark.types import DecimalType, FloatType\n\n# Get schema of the DataFrame\nschema = spdf.schema.fields\n\n# Identify columns that are of type NUMBER (DecimalType)\nnum_columns = [col.name for col in schema if isinstance(col.datatype, DecimalType)]\n\n# Convert columns to FLOAT\nfor col in num_columns:\n    spdf = spdf.with_column(col, spdf[col].cast(FloatType()))\n\n\nfrom snowflake.snowpark.functions import col, current_date, dateadd, to_date, lit,to_timestamp\nfrom datetime import datetime\n\n# Step 1: Get today's date\ntodays_date = datetime.now()\n\n# Ensure TRANSACTIONTIMESTAMP is stored as a string first\nspdf = spdf.with_column(\"TRANSACTIONTIMESTAMP\", col(\"TRANSACTIONTIMESTAMP\").cast(\"string\"))\n\n# Get the latest date from the dataset\nlatest_date_str = max(spdf.select('TRANSACTIONTIMESTAMP').collect())[0]\n\n# Convert latest_date to datetime\nlatest_date = datetime.strptime(latest_date_str, '%m/%d/%y %H:%M')\n\n# Step 3: Calculate the difference in days\ndiff_days = (todays_date - latest_date).days - 1\n\n# Apply date adjustment\ndf = spdf.with_column(\n    \"TRANSACTIONTIMESTAMP\",\n    dateadd(\"day\", lit(diff_days), to_timestamp(col(\"TRANSACTIONTIMESTAMP\"), 'MM/DD/YY HH24:MI'))\n)\n\n# Cast CREDIT SCORE to float\ndf = df.with_column(\"CREDITSCORE\", col(\"CREDITSCORE\").cast(\"float\"))\n\n# Add PREDICTED_CHURN column\nspdf_drift = df.with_column(\"PREDICTED_CHURN\", lit(9999))\n\nspdf_drift.show()\n",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "e292f2b9-e023-4d96-bef2-f183ebf97fe6",
   "metadata": {
    "name": "mk1",
    "collapsed": false
   },
   "source": "La firma financiera realiza las predicciones con la deriva de datos usando la versi√≥n v1 del modelo. Los datos derivados se guardan en la tabla CUSTOMERS_DRIFTED. Una copia de los mismos datos se guarda en la tabla CUSTOMERS_EVAL para mostrar c√≥mo se monitoriz√≥ esa deriva y se reentren√≥ un nuevo modelo de forma proactiva para evitar la toma de decisiones inexactas."
  },
  {
   "cell_type": "code",
   "id": "91d791e8-e863-4842-b7f8-835a12072837",
   "metadata": {
    "language": "python",
    "name": "CUSTOMERS_DRIFTED_table",
    "collapsed": false
   },
   "outputs": [],
   "source": "\ncurrent_columns = spdf_drift.columns \nnew_columns = [col.strip('\"') for col in current_columns] \n\nspdf_drift = spdf_drift.select([spdf_drift[col].alias(new_col) for col, new_col in zip(current_columns, new_columns)])\nspdf_drift = spdf_drift.with_column(\n    \"CREDITSCORE\", col(\"CREDITSCORE\").cast(\"float\")\n)\nspdf_drift.write.mode(\"overwrite\").save_as_table(\"CUSTOMERS_DRIFTED\")\nspdf_drift.write.mode(\"overwrite\").save_as_table(\"CUSTOMERS_EVAL\")\n",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "a5ce8079-4ddd-41df-a8cb-b867deb7098b",
   "metadata": {
    "collapsed": false,
    "name": "DEMO____Monitoring",
    "resultHeight": 115
   },
   "source": "# Habilitar la Monitorizaci√≥n\nCrea un monitor para sus modelos utilizando el comando CREATE MODEL MONITOR. El objeto monitor refresca autom√°ticamente los registros del monitor consultando los datos de origen y actualiza los informes de monitorizaci√≥n bas√°ndose en los registros. El primero que est√° comentado muestra el m√©todo Pythonic y la siguiente celda muestra c√≥mo monitorizar usando SQL."
  },
  {
   "cell_type": "code",
   "id": "9a75f3e5-e8b1-495a-bb89-522f2f8dc191",
   "metadata": {
    "language": "python",
    "name": "pythonic_modelmonitor",
    "collapsed": true,
    "codeCollapsed": false
   },
   "outputs": [],
   "source": "'''\nreg = Registry(session=session,options={\"enable_monitoring\": True})\nmodelname='QS_CustomerChurn_classifier'\nmodelversion='v1'\nm = reg.get_model(modelname)\nmv = m.version(modelversion)\n\n# Fetch model version that will be monitored\nmodel_version = mv\n\nfrom snowflake.ml.monitoring.entities.model_monitor_config import ModelMonitorConfig, ModelMonitorSourceConfig\nsource_config = ModelMonitorSourceConfig(\n    source=\"CUSTOMERS_DRIFTED\",\n    baseline=\"CUSTOMERS\",\n    timestamp_column=\"TRANSACTIONTIMESTAMP\",\n    prediction_class_columns=[\"PREDICTED_CHURN\"],\n    actual_class_columns=[\"EXITED\"],\n    id_columns=[\"CUSTOMERID\"],\n)\n\n# Set up config for ModelMonitor.\nmodel_monitor_config = ModelMonitorConfig(\n    model_version=model_version,\n    model_function_name=\"predict\",\n    background_compute_warehouse_name=\"ml_wh\",\n)\n\n# Add a new ModelMonitor\nmodel_monitor = reg.add_monitor(\n    name=f\"CHURN_MODEL_MONITOR\", \n    source_config=source_config,\n    model_monitor_config=model_monitor_config,\n)\nmodel_monitor\n'''",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "4feedabf-0d1b-4efa-af01-9b3a38df68ea",
   "metadata": {
    "name": "sqlmm",
    "collapsed": false
   },
   "source": "## Versi√≥n SQL para crear el monitor del modelo"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2047644f-ab0a-4447-b573-2afd3c20f739",
   "metadata": {
    "language": "python",
    "name": "DEMO____ADD_MONITOR",
    "resultHeight": 111,
    "collapsed": false
   },
   "outputs": [],
   "source": "query = f\"\"\"\nCREATE OR REPLACE MODEL MONITOR CHURN_MODEL_MONITOR\nWITH\n    MODEL=QS_CustomerChurn_classifier\n    VERSION=v1\n    FUNCTION=predict\n    SOURCE=CUSTOMERS_DRIFTED\n    BASELINE=CUSTOMERS\n    TIMESTAMP_COLUMN=TRANSACTIONTIMESTAMP\n    PREDICTION_CLASS_COLUMNS=(PREDICTED_CHURN)  \n    ACTUAL_CLASS_COLUMNS=(EXITED)\n    ID_COLUMNS=(CUSTOMERID)\n    WAREHOUSE=ML_WH\n    REFRESH_INTERVAL='1 min'\n    AGGREGATION_WINDOW='1 day';\n\"\"\"\nsession.sql(query).collect()"
  },
  {
   "cell_type": "markdown",
   "id": "8bb50723-976e-4be4-934a-2845f4208a6b",
   "metadata": {
    "name": "predict2",
    "collapsed": false
   },
   "source": "\n## Predecir el churn (abandono) para las nuevas tendencias de clientes"
  },
  {
   "cell_type": "code",
   "id": "1df4e58d-10a2-4754-a750-6018310caf4f",
   "metadata": {
    "language": "python",
    "name": "inference_1",
    "collapsed": false
   },
   "outputs": [],
   "source": "status= inference('CUSTOMERS_DRIFTED','QS_CUSTOMERCHURN_CLASSIFIER', 'v1');",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "9c9e6b74-699e-4b7a-b281-0aa6ca925b79",
   "metadata": {
    "collapsed": false,
    "name": "DEMO____Dashboard",
    "resultHeight": 83
   },
   "source": "Veamos c√≥mo se ven las predicciones de abandono y las m√©tricas. \n\nAbre el Panel navegando a Studio->Models.\n\nHaz clic en tu modelo y elige el monitor que acabas de a√±adir arriba. Cambia el rango de fechas a \"√öltimos 3 meses\"."
  },
  {
   "cell_type": "code",
   "id": "dc285676-763b-4bf8-91e9-b123f2774e84",
   "metadata": {
    "language": "sql",
    "name": "RETRAINING_DATA",
    "collapsed": false
   },
   "outputs": [],
   "source": "-- Create csv format\nCREATE FILE FORMAT IF NOT EXISTS CSVFORMAT \n    SKIP_HEADER = 1 \n    TYPE = 'CSV';\n    \nCREATE OR REPLACE STAGE data_stage\n    FILE_FORMAT = (TYPE = 'CSV') \n    URL = 's3://sfquickstarts/sfguide_getting_started_with_ml_observability_in_snowflake/CUSTOMERS_TRAINING.csv';\n    \n-- Inspect content of stage\nLS @data_stage;\n",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "0d39a9f9-be64-491d-8df3-595c3bbf51d6",
   "metadata": {
    "name": "mkretrain",
    "collapsed": false
   },
   "source": "## Se puede encontrar que la deriva de datos y la deriva de concepto han impactado significativamente el rendimiento del modelo con el tiempo.\n\nPara mantener la precisi√≥n, los modelos requieren reentrenamiento peri√≥dicamente. A continuaci√≥n se muestra c√≥mo se maneja esto en el pipeline de predicci√≥n de abandono de clientes. Ahora reentrenemos los datos con las nuevas tendencias."
  },
  {
   "cell_type": "code",
   "id": "1e71c4a1-fd06-42c5-8af7-1483ce44fae3",
   "metadata": {
    "language": "python",
    "name": "preprocess_retraining_data",
    "collapsed": false
   },
   "outputs": [],
   "source": "spdf = session.read.options({\"field_delimiter\": \",\",\n                                    \"field_optionally_enclosed_by\": '\"',\n                                    \"infer_schema\": True,\n                                    \"parse_header\": True}).csv(\"@data_stage\")\n\nfrom snowflake.snowpark.types import DecimalType, FloatType\n\n# Get schema of the DataFrame\nschema = spdf.schema.fields\n\n# Identify columns that are of type NUMBER (DecimalType)\nnum_columns = [col.name for col in schema if isinstance(col.datatype, DecimalType)]\n\n# Convert columns to FLOAT\nfor col in num_columns:\n    spdf = spdf.with_column(col, spdf[col].cast(FloatType()))\n\n\nfrom snowflake.snowpark.functions import col, current_date, dateadd, to_date, lit,to_timestamp\nfrom datetime import datetime\n\n# Step 1: Get today's date\ntodays_date = datetime.now()\n\n# Ensure TRANSACTIONTIMESTAMP is stored as a string first\nspdf = spdf.with_column(\"TRANSACTIONTIMESTAMP\", col(\"TRANSACTIONTIMESTAMP\").cast(\"string\"))\n\n# Get the latest date from the dataset\nlatest_date_str = max(spdf.select('TRANSACTIONTIMESTAMP').collect())[0]\n\n# Convert latest_date to datetime\nlatest_date = datetime.strptime(latest_date_str, '%m/%d/%y %H:%M')\n\n# Step 3: Calculate the difference in days\ndiff_days = (todays_date - latest_date).days - 1\n\n# Apply date adjustment\ndf = spdf.with_column(\n    \"TRANSACTIONTIMESTAMP\",\n    dateadd(\"day\", lit(diff_days), to_timestamp(col(\"TRANSACTIONTIMESTAMP\"), 'MM/DD/YY HH24:MI'))\n)\n\n# Cast CREDIT SCORE to float\ndf = df.with_column(\"CREDITSCORE\", col(\"CREDITSCORE\").cast(\"float\"))\n\n# Add PREDICTED_CHURN column\nspdf_drift = df.with_column(\"PREDICTED_CHURN\", lit(9999))\n\nspdf_drift.show()\n\ncurrent_columns = spdf_drift.columns \nnew_columns = [col.strip('\"') for col in current_columns] \n\nspdf_drift = spdf_drift.select([spdf_drift[col].alias(new_col) for col, new_col in zip(current_columns, new_columns)])\nspdf_drift = spdf_drift.with_column(\n    \"CREDITSCORE\", col(\"CREDITSCORE\").cast(\"float\")\n)\n\n\nspdf_drift.write.mode(\"overwrite\").save_as_table(\"CUSTOMERS_TRAINING\")\n",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "9a756567-1ec8-454b-b58d-d7c037f8d01c",
   "metadata": {
    "language": "python",
    "name": "retrain_model",
    "collapsed": false
   },
   "outputs": [],
   "source": "# Load preprocessing pipeline from a file\nsession.file.get('@ML_STAGE/preprocessing_pipeline.joblib.gz', '/tmp')\npipeline_file = '/tmp/preprocessing_pipeline.joblib.gz'\n\n\npreprocessing_pipeline = joblib.load(pipeline_file)\n\n# Apply preprocessing\ntraining_spdf = preprocessing_pipeline.fit(spdf_drift).transform(spdf_drift)\ntraining_spdf = training_spdf.with_column(\n\"CREDITSCORE_SS\", col(\"CREDITSCORE_SS\").cast(\"float\")\n)\n\nnum_cols = ['EstimatedSalary', 'Balance', 'CreditScore','Age','Tenure','debttoincome']\n\ncat_cols = ['HasCrCard', 'IsActiveMember', 'GEOGRAPHY','GENDER', 'NumOfProducts']\nTarget = [\"EXITED\"]\n\nfeature_names_input = [c for c in training_spdf.columns if c not in [\"EXITED\", \"TRANSACTIONTIMESTAMP\", \"CUSTOMERID\",\"ESTIMATEDSALARY\", \"BALANCE\", \"CREDITSCORE\",\"AGE\",\"TENURE\",\"DEBTTOINCOME\",\"GEOGRAPHY\",\"GENDER\",\"PREDICTED_CHURN\",\"DATASET_TYPE\"]]\n\noutput_label = [\"PREDICTED_CHURN\"]\n# Initialize a XGBClassifier object with input, label, and output column names\nmodel = XGBClassifier(\n    input_cols=feature_names_input,\n    label_cols=Target,\n    output_cols=output_label\n    \n)\n\n# Train the classifier model using the training set\n_ = model.fit(training_spdf)\n",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "fb0bedb9-b8b6-4f3f-ba56-66e59ef5d678",
   "metadata": {
    "name": "mk",
    "collapsed": false
   },
   "source": "## Registrar el modelo como una nueva versi√≥n V2 con el mismo nombre de modelo QS_CustomerChurn_classifier"
  },
  {
   "cell_type": "code",
   "id": "9a004951-afdc-4461-8d5e-efc2d4d4fef1",
   "metadata": {
    "language": "python",
    "name": "QS_CustomerChurn_classifier_v2",
    "collapsed": false
   },
   "outputs": [],
   "source": "from snowflake.ml.registry import Registry\nfrom snowflake.ml.model import type_hints\n\nreg = Registry(session=session)\n\nMODEL_NAME = \"QS_CustomerChurn_classifier\"\nMODEL_VERSION = \"v2\"\n\nmv = reg.log_model(model,\n                   model_name=MODEL_NAME,\n                   version_name=MODEL_VERSION,\n                   options={'relax_version': True},\n                   task=type_hints.Task.TABULAR_BINARY_CLASSIFICATION)\nreg.show_models()\n",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "cdbf1034-3a65-4202-bb66-e5662ffa21bf",
   "metadata": {
    "name": "modelmonitor",
    "collapsed": false
   },
   "source": "\n## Crear un monitor para la nueva versi√≥n del modelo"
  },
  {
   "cell_type": "code",
   "id": "a6237f55-a907-4a97-ace3-d585bf0823c8",
   "metadata": {
    "language": "python",
    "name": "CHURN_MODEL_MONITOR_NEW",
    "collapsed": false
   },
   "outputs": [],
   "source": "query = f\"\"\"\nCREATE OR REPLACE MODEL MONITOR CHURN_MODEL_MONITOR_NEW\nWITH\n    MODEL=QS_CustomerChurn_classifier\n    VERSION=v2\n    FUNCTION=predict\n    SOURCE=CUSTOMERS_EVAL\n    BASELINE=CUSTOMERS_TRAINING\n    TIMESTAMP_COLUMN=TRANSACTIONTIMESTAMP\n    PREDICTION_CLASS_COLUMNS=(PREDICTED_CHURN)  \n    ACTUAL_CLASS_COLUMNS=(EXITED)\n    ID_COLUMNS=(CUSTOMERID)\n    WAREHOUSE=ML_WH\n    REFRESH_INTERVAL='1 min'\n    AGGREGATION_WINDOW='1 day';\n\"\"\"\nsession.sql(query).collect()",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "bf3a4231-7898-437e-ba01-534e407846d2",
   "metadata": {
    "name": "inference3",
    "collapsed": false
   },
   "source": "## Predecir el abandono con los nuevos datos de clientes utilizando el modelo reentrenado"
  },
  {
   "cell_type": "code",
   "id": "56381f7a-8ba7-4d84-9418-f0a974e4d747",
   "metadata": {
    "language": "python",
    "name": "inference_2",
    "collapsed": false
   },
   "outputs": [],
   "source": "status= inference('CUSTOMERS_EVAL','QS_CUSTOMERCHURN_CLASSIFIER', 'v2');",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "dbb3e3d2-e91b-4b72-822a-24bc81bb7986",
   "metadata": {
    "name": "MODEL_MONITOR_STAT_METRIC",
    "collapsed": false
   },
   "source": "### Recuperar los res√∫menes estad√≠sticos de una caracter√≠stica, etiqueta o predicci√≥n del modelo de un modelo monitorizado a lo largo del tiempo.\nüîπ Caso de Uso: Ayuda a analizar tendencias en el rendimiento del modelo, el comportamiento de las caracter√≠sticas y la distribuci√≥n de las predicciones. El Nombre de la M√©trica podr√≠a ser {'COUNT', 'COUNT_NULL'}\n### La granularidad puede ser de cualquier forma ‚Äò<num> {DAY, WEEK, MONTH, QUARTER, YEAR}‚Äô, ALL o NULL"
  },
  {
   "cell_type": "code",
   "id": "2c7a1cf5-e8b0-4ef4-bf77-10ae24476830",
   "metadata": {
    "language": "sql",
    "name": "FEATURE_ML_MONITORING_METRICS_API",
    "collapsed": false
   },
   "outputs": [],
   "source": "\nSELECT * FROM \nTABLE(\nMODEL_MONITOR_STAT_METRIC(\n'CHURN_MODEL_MONITOR', 'COUNT', 'PREDICTED_CHURN', '1 DAY', TO_TIMESTAMP_TZ('2024-11-01'), TO_TIMESTAMP_TZ('2025-02-06'))\n) as a\nJOIN (SELECT * FROM \nTABLE(\nMODEL_MONITOR_STAT_METRIC(\n'CHURN_MODEL_MONITOR_NEW', 'COUNT', 'PREDICTED_CHURN', '1 DAY', TO_TIMESTAMP_TZ('2024-11-01'), TO_TIMESTAMP_TZ('2025-02-06'))\n)) as b ON a.EVENT_TIMESTAMP = b.EVENT_TIMESTAMP;\n",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "60655c57-1238-4097-9bcb-18e1bb18f098",
   "metadata": {
    "name": "MKMODEL_MONITOR_DRIFT_METRIC",
    "collapsed": false
   },
   "source": "### Calcular m√©tricas de deriva para una caracter√≠stica, etiqueta o predicci√≥n del modelo especificada durante un per√≠odo de tiempo dado.\nEsto ayuda a detectar cambios en las distribuciones de datos (deriva de caracter√≠sticas) o cambios en las predicciones (deriva de concepto)."
  },
  {
   "cell_type": "code",
   "id": "e61e700c-b3ef-4189-b849-6dfe04f9eeaa",
   "metadata": {
    "language": "sql",
    "name": "MODEL_MONITOR_DRIFT_METRIC",
    "collapsed": false
   },
   "outputs": [],
   "source": "\nSELECT * FROM TABLE(MODEL_MONITOR_DRIFT_METRIC(\n'CHURN_MODEL_MONITOR_NEW', 'DIFFERENCE_OF_MEANS', 'PREDICTED_CHURN', '1 DAY', TO_TIMESTAMP_TZ('2025-02-01'), TO_TIMESTAMP_TZ('2025-02-04')))",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "58592dd9-9fd0-40a8-bd5c-1e7c7bee1115",
   "metadata": {
    "name": "performance_metrics",
    "collapsed": false
   },
   "source": "### Prop√≥sito: Obtiene m√©tricas de rendimiento para un modelo monitorizado en un rango de tiempo especificado.\nüîπ Caso de Uso: Permite realizar un seguimiento de c√≥mo ha evolucionado el rendimiento del modelo (por ejemplo, ca√≠das de precisi√≥n o degradaci√≥n del rendimiento)."
  },
  {
   "cell_type": "code",
   "id": "0b8989d5-db2d-49c1-863b-7ea0d8f43fb0",
   "metadata": {
    "language": "sql",
    "name": "MODEL_MONITOR_PERFORMANCE_METRIC",
    "collapsed": false
   },
   "outputs": [],
   "source": "SELECT * FROM TABLE(MODEL_MONITOR_PERFORMANCE_METRIC(\n'CHURN_MODEL_MONITOR_NEW', 'PRECISION', '1 DAY', TO_TIMESTAMP_TZ('2024-11-01'), TO_TIMESTAMP_TZ('2025-02-05')))",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "27bb4ee0-07e5-4c11-aac8-bf7970e58451",
   "metadata": {
    "name": "setup_alert",
    "collapsed": false
   },
   "source": "### Configuraci√≥n de Alertas"
  },
  {
   "cell_type": "markdown",
   "id": "ca6f26f8-ce8a-41f0-9998-f9748f776ff3",
   "metadata": {
    "name": "TEST_NOTIFICATION",
    "collapsed": false
   },
   "source": "Configurar Alertas para recibir notificaciones cuando una m√©trica determinada supera el l√≠mite de umbral."
  },
  {
   "cell_type": "code",
   "id": "87216d35-8600-41a8-bfff-efcf5e545e04",
   "metadata": {
    "language": "python",
    "name": "test_notification_table",
    "collapsed": false
   },
   "outputs": [],
   "source": "query=f'''CREATE or replace TABLE TEST_NOTIFICATION(\n    notification varchar (100),\n    created_at timestamp\n);'''\n\nsession.sql(query).collect()",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "f1bb686f-099a-43c6-8420-0b017501a904",
   "metadata": {
    "language": "sql",
    "name": "high_drift_alert",
    "collapsed": false
   },
   "outputs": [],
   "source": "CREATE OR REPLACE ALERT high_drift_alert\n    WAREHOUSE = ML_WH\n    SCHEDULE = '60 minutes'\n    IF ( EXISTS (SELECT * FROM TABLE(MODEL_MONITOR_DRIFT_METRIC(\n    'CHURN_MODEL_MONITOR', 'DIFFERENCE_OF_MEANS', 'PREDICTED_CHURN', '1 MONTH', TO_TIMESTAMP_TZ('2024-01-01'), TO_TIMESTAMP_TZ('2025-02-04')))))\n    THEN\n        INSERT INTO TEST_NOTIFICATION (notification, created_at) VALUES ('ALERT',(SELECT CURRENT_TIMESTAMP));",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "d89e2468-938a-4e17-bdb6-1706001133f2",
   "metadata": {
    "name": "end",
    "collapsed": false
   },
   "source": "## Fin del Notebook"
  }
 ]
}
