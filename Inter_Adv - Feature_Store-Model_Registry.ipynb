{
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  },
  "lastEditStatus": {
   "notebookId": "rka5xmgybjmutwwe6z5o",
   "authorId": "1126630220347",
   "authorName": "JPARRADO",
   "authorEmail": "jorge.parrado@snowflake.com",
   "sessionId": "a05ea330-69fa-4080-8394-99c4b56d5bc5",
   "lastEditTime": 1746603892513
  }
 },
 "nbformat_minor": 5,
 "nbformat": 4,
 "cells": [
  {
   "cell_type": "markdown",
   "id": "11e61f12-d0e2-4553-9472-e92da5b1e80c",
   "metadata": {
    "name": "cell1",
    "collapsed": false
   },
   "source": "# [Snowflake ML](https://www.snowflake.com/en/data-cloud/snowflake-ml/)\nConjunto integrado de capacidades endo-to-end para ML en una única plataforma sobre sus datos gobernados. \nLos científicos de datos e ingenieros de ML pueden desarrollar y poner en producción características y modelos escalables de manera fácil y segura sin movimiento de datos, silos o compromisos de gobernanza. La librería Snowpark ML Python (el paquete snowflake-ml-python) proporciona APIs para desarrollar e implementar sus pipelines de Snowflake ML.\n\nEsta es la parte 3 de una serie de inicio rápido de introducción de 3 partes a Snowflake Feature Store (vea la parte 1 [aquí](https://quickstarts.snowflake.com/guide/intro-to-feature-store/index.html#0) y la parte 2 [aquí](https://quickstarts.snowflake.com/guide/overview-of-feature-store-api/index.html?index=..%2F..index#0)). Este inicio rápido demuestra un ciclo completo de experimento de ML de principio a fin, incluyendo la creación de características, la generación de datos de entrenamiento, el entrenamiento del modelo y la inferencia. El flujo de trabajo aborda características clave de Snowflake ML, incluyendo [Snowflake Feature Store](https://docs.snowflake.com/en/developer-guide/snowpark-ml/feature-store/overview), [Dataset](https://docs.snowflake.com/en/developer-guide/snowpark-ml/dataset), [APIs de Snowflake ML](https://docs.snowflake.com/en/developer-guide/snowpark-ml/modeling) y [Snowflake Model Registry](https://docs.snowflake.com/en/developer-guide/snowpark-ml/model-registry/overview).\n\n\n[Fuente](https://quickstarts.snowflake.com/guide/develop-and-manage-ml-models-with-feature-store-and-model-registry/index.html?index=..%2F..index#0)"
  },
  {
   "cell_type": "markdown",
   "id": "e2ddf336-59f3-47bd-b745-d4768364a384",
   "metadata": {
    "collapsed": false,
    "name": "overview_md"
   },
   "source": "# Desarrollar y Administrar Modelos ML con Feature Store y Model Registry\n\nEste notebook muestra un ciclo completo de experimentación de ML de principio a fin, incluyendo la creación de características, la generación de datos de entrenamiento, el entrenamiento del modelo y la inferencia. El flujo de trabajo aborda características clave de Snowflake ML, incluyendo [Snowflake Feature Store](https://docs.snowflake.com/en/developer-guide/snowpark-ml/feature-store/overview), [Dataset](https://docs.snowflake.com/en/developer-guide/snowpark-ml/dataset), [Snowpark ML Modeling](https://docs.snowflake.com/en/developer-guide/snowpark-ml/modeling) y [Snowflake Model Registry](https://docs.snowflake.com/en/developer-guide/snowpark-ml/model-registry/overview).\n\nNota: Asegúrese de que `snowflake-ml-python` y `snowflake-snowpark-python` estén instalados desde el menú desplegable de paquetes.\n\n**Tabla de contenidos**\n- Configurar entorno de prueba\n  - Conectar a Snowflake\n  - Seleccionar su ejemplo\n- Crear características con Feature Store\n  - Inicializar Feature Store\n  - Registrar entidades y vistas de características\n  - Examinar características en la UI de Snowflake\n- Generar Datos de Entrenamiento\n- Entrenar modelo con Snowpark ML\n- Registrar modelos en Model Registry\n  - Examinar modelo en la UI de Snowflake\n- Predecir con el modelo\n  - Predecir con modelo local\n  - Predecir con Model Registry\n"
  },
  {
   "cell_type": "markdown",
   "id": "56b7406a-828f-46d0-acfe-7f0e10f7c03d",
   "metadata": {
    "collapsed": false,
    "name": "setup_md"
   },
   "source": "## Configurar entorno de prueba\n\n### Conectar a Snowflake\n\nComencemos configurando nuestro entorno de prueba"
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "96f3bf5a-9758-4341-ba46-c8399b502175",
   "metadata": {
    "codeCollapsed": false,
    "collapsed": false,
    "language": "python",
    "name": "setup_notebook"
   },
   "outputs": [],
   "source": "from snowflake.snowpark.context import get_active_session\nsession = get_active_session()\n\n# Add a query tag to the session. This helps with debugging and performance monitoring.\nsession.query_tag = {\"origin\":\"sf_sit-is\", \"name\":\"aiml_notebooks_develop_models_with_feature_store\", \"version\":{\"major\":1, \"minor\":0}, \"attributes\":{\"is_quickstart\":1, \"source\":\"notebook\"}}\n\n# Set session context \n# session.use_role(\"ML_MODEL_ROLE\") \n\n# Print the current role, warehouse, and database/schema\nprint(f\"role: {session.get_current_role()} | WH: {session.get_current_warehouse()} | DB.SCHEMA: {session.get_fully_qualified_current_schema()}\")\n\nimport warnings\nwarnings.filterwarnings('ignore')"
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1f38d70d-ccc2-40b9-8020-50e3ad3ff165",
   "metadata": {
    "collapsed": false,
    "language": "python",
    "name": "set_schemas"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(status='Schema SNOWFLAKE_FEATURE_STORE_NOTEBOOK_DEMO successfully created.')]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The schema where Feature Store will initialize on and test dataset stores.\n",
    "FS_DEMO_SCHEMA = session.get_current_schema()\n",
    "# the schema where the model lives.\n",
    "MODEL_DEMO_SCHEMA = session.get_current_schema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b3f89f3-d84d-4226-830d-3a967499fed7",
   "metadata": {
    "collapsed": false,
    "name": "select_example_md"
   },
   "source": "### Seleccionar su ejemplo\n\nHemos preparado algunos ejemplos que puede encontrar en nuestro [repositorio de código abierto](https://github.com/snowflakedb/snowflake-ml-python/tree/main/snowflake/ml/feature_store/examples). Cada ejemplo contiene el conjunto de datos de origen, la vista de características y las definiciones de entidad que se utilizarán en esta demostración. `ExampleHelper` (incluido en snowflake-ml-python) configurará todo con APIs simples y no tendrá que preocuparse por los detalles."
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2cbb04de-193c-44e1-b400-802e22eb6941",
   "metadata": {
    "codeCollapsed": false,
    "collapsed": false,
    "language": "python",
    "name": "example_list"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>NAME</th>\n",
       "      <th>DESC</th>\n",
       "      <th>LABEL_COLS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>new_york_taxi_features</td>\n",
       "      <td>Features using taxi trip data trying to predic...</td>\n",
       "      <td>TOTAL_AMOUNT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>airline_features</td>\n",
       "      <td>Features using synthetic airline data to predi...</td>\n",
       "      <td>DEPARTING_DELAY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>citibike_trip_features</td>\n",
       "      <td>Features using citibike trip data trying to pr...</td>\n",
       "      <td>tripduration</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>wine_quality_features</td>\n",
       "      <td>Features using wine quality data trying to pre...</td>\n",
       "      <td>quality</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     NAME                                               DESC  \\\n",
       "0  new_york_taxi_features  Features using taxi trip data trying to predic...   \n",
       "1        airline_features  Features using synthetic airline data to predi...   \n",
       "2  citibike_trip_features  Features using citibike trip data trying to pr...   \n",
       "3   wine_quality_features  Features using wine quality data trying to pre...   \n",
       "\n",
       "        LABEL_COLS  \n",
       "0     TOTAL_AMOUNT  \n",
       "1  DEPARTING_DELAY  \n",
       "2     tripduration  \n",
       "3          quality  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from snowflake.ml.feature_store.examples.example_helper import ExampleHelper\n",
    "\n",
    "example_helper = ExampleHelper(session, session.get_current_database(), FS_DEMO_SCHEMA)\n",
    "example_helper.list_examples().to_pandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f909c72-e3c0-4834-a935-24a689101979",
   "metadata": {
    "collapsed": false,
    "name": "load_example_md"
   },
   "source": "`load_example()` cargará los datos de origen en tablas de Snowflake. En el ejemplo siguiente, estamos utilizando el ejemplo \"new_york_taxi_features\". Puede reemplazarlo con cualquier ejemplo listado anteriormente. La ejecución de la celda siguiente puede tardar algún tiempo dependiendo del tamaño del conjunto de datos."
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "42c12da2-71cc-4c90-89aa-b1bd474ae975",
   "metadata": {
    "codeCollapsed": false,
    "collapsed": false,
    "language": "python",
    "name": "load_example"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"AIRLINE_FEATURE_STORE\".SNOWFLAKE_FEATURE_STORE_NOTEBOOK_DEMO.nyc_yellow_trips:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>VENDORID</th>\n",
       "      <th>PASSENGER_COUNT</th>\n",
       "      <th>TRIP_DISTANCE</th>\n",
       "      <th>RATECODEID</th>\n",
       "      <th>STORE_AND_FWD_FLAG</th>\n",
       "      <th>PULOCATIONID</th>\n",
       "      <th>DOLOCATIONID</th>\n",
       "      <th>PAYMENT_TYPE</th>\n",
       "      <th>FARE_AMOUNT</th>\n",
       "      <th>EXTRA</th>\n",
       "      <th>MTA_TAX</th>\n",
       "      <th>TIP_AMOUNT</th>\n",
       "      <th>TOLLS_AMOUNT</th>\n",
       "      <th>IMPROVEMENT_SURCHARGE</th>\n",
       "      <th>TOTAL_AMOUNT</th>\n",
       "      <th>CONGESTION_SURCHARGE</th>\n",
       "      <th>AIRPORT_FEE</th>\n",
       "      <th>TPEP_PICKUP_DATETIME</th>\n",
       "      <th>TPEP_DROPOFF_DATETIME</th>\n",
       "      <th>TRIP_ID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.65</td>\n",
       "      <td>1</td>\n",
       "      <td>N</td>\n",
       "      <td>238</td>\n",
       "      <td>238</td>\n",
       "      <td>2</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>5.8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2016-01-07 17:53:47</td>\n",
       "      <td>2016-01-07 17:55:29</td>\n",
       "      <td>2195456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1.24</td>\n",
       "      <td>1</td>\n",
       "      <td>N</td>\n",
       "      <td>138</td>\n",
       "      <td>70</td>\n",
       "      <td>2</td>\n",
       "      <td>7.5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>9.3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2016-01-07 17:37:22</td>\n",
       "      <td>2016-01-07 17:46:17</td>\n",
       "      <td>2195457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.90</td>\n",
       "      <td>1</td>\n",
       "      <td>N</td>\n",
       "      <td>161</td>\n",
       "      <td>229</td>\n",
       "      <td>2</td>\n",
       "      <td>6.5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>8.3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2016-01-07 17:08:42</td>\n",
       "      <td>2016-01-07 17:16:12</td>\n",
       "      <td>2195458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2.50</td>\n",
       "      <td>1</td>\n",
       "      <td>N</td>\n",
       "      <td>162</td>\n",
       "      <td>262</td>\n",
       "      <td>1</td>\n",
       "      <td>12.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>14.8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2016-01-07 17:27:16</td>\n",
       "      <td>2016-01-07 17:42:22</td>\n",
       "      <td>2195459</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.20</td>\n",
       "      <td>1</td>\n",
       "      <td>N</td>\n",
       "      <td>262</td>\n",
       "      <td>141</td>\n",
       "      <td>2</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>9.8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2016-01-07 17:46:03</td>\n",
       "      <td>2016-01-07 17:56:03</td>\n",
       "      <td>2195460</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   VENDORID  PASSENGER_COUNT  TRIP_DISTANCE  RATECODEID STORE_AND_FWD_FLAG  \\\n",
       "0         2                1           0.65           1                  N   \n",
       "1         2                1           1.24           1                  N   \n",
       "2         1                1           0.90           1                  N   \n",
       "3         1                1           2.50           1                  N   \n",
       "4         1                1           1.20           1                  N   \n",
       "\n",
       "   PULOCATIONID  DOLOCATIONID  PAYMENT_TYPE  FARE_AMOUNT  EXTRA  MTA_TAX  \\\n",
       "0           238           238             2          4.0    1.0      0.5   \n",
       "1           138            70             2          7.5    1.0      0.5   \n",
       "2           161           229             2          6.5    1.0      0.5   \n",
       "3           162           262             1         12.0    1.0      0.5   \n",
       "4           262           141             2          8.0    1.0      0.5   \n",
       "\n",
       "   TIP_AMOUNT  TOLLS_AMOUNT  IMPROVEMENT_SURCHARGE  TOTAL_AMOUNT  \\\n",
       "0         0.0           0.0                    0.3           5.8   \n",
       "1         0.0           0.0                    0.3           9.3   \n",
       "2         0.0           0.0                    0.3           8.3   \n",
       "3         1.0           0.0                    0.3          14.8   \n",
       "4         0.0           0.0                    0.3           9.8   \n",
       "\n",
       "   CONGESTION_SURCHARGE  AIRPORT_FEE TPEP_PICKUP_DATETIME  \\\n",
       "0                   NaN          NaN  2016-01-07 17:53:47   \n",
       "1                   NaN          NaN  2016-01-07 17:37:22   \n",
       "2                   NaN          NaN  2016-01-07 17:08:42   \n",
       "3                   NaN          NaN  2016-01-07 17:27:16   \n",
       "4                   NaN          NaN  2016-01-07 17:46:03   \n",
       "\n",
       "  TPEP_DROPOFF_DATETIME  TRIP_ID  \n",
       "0   2016-01-07 17:55:29  2195456  \n",
       "1   2016-01-07 17:46:17  2195457  \n",
       "2   2016-01-07 17:16:12  2195458  \n",
       "3   2016-01-07 17:42:22  2195459  \n",
       "4   2016-01-07 17:56:03  2195460  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# replace the value with the example you want to run\n",
    "source_tables = example_helper.load_example('new_york_taxi_features')\n",
    "\n",
    "# display as Pandas DataFrame\n",
    "for table in source_tables:\n",
    "    print(f\"{table}:\")\n",
    "    df = session.table(table).limit(5).to_pandas()\n",
    "    df.style"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "068b29b4-24f4-4984-b348-f7087b7a6b20",
   "metadata": {
    "collapsed": false,
    "name": "feature_store_md"
   },
   "source": "## Crear características con Feature Store\n\n### Inicializar Feature Store\n\nPrimero, creemos un cliente de feature store. Con el modo `CREATE_IF_NOT_EXIST`, intentará crear un nuevo esquema de Feature Store y todos los metadatos necesarios de feature store si aún no existen. Es necesario por primera vez configurar un Feature Store. Después, puede usar el modo `FAIL_IF_NOT_EXIST` para conectarse a un Feature Store existente.\n\nTenga en cuenta que la base de datos que se está utilizando ya debe existir. Feature Store **NO** intentará crear la base de datos incluso en el modo `CREATE_IF_NOT_EXIST`."
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7ff64e3c-6445-486e-a0fe-2949c973e0ee",
   "metadata": {
    "codeCollapsed": false,
    "collapsed": false,
    "language": "python",
    "name": "initialize_feature_store"
   },
   "outputs": [],
   "source": [
    "from snowflake.ml.feature_store import (\n",
    "    FeatureStore,\n",
    "    FeatureView,\n",
    "    Entity,\n",
    "    CreationMode\n",
    ")\n",
    "\n",
    "fs = FeatureStore(\n",
    "    session=session, \n",
    "    database=session.get_current_database(), \n",
    "    name=FS_DEMO_SCHEMA, \n",
    "    default_warehouse=session.get_current_warehouse(),\n",
    "    creation_mode=CreationMode.CREATE_IF_NOT_EXIST,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c642cda-4a95-47e0-93f6-8f9dde285ff4",
   "metadata": {
    "collapsed": false,
    "name": "register_entities_and_feature_views_md"
   },
   "source": "### Registrar entidades y vistas de características\n\nA continuación, registramos nuevas entidades y vistas de características en Feature Store. Las entidades serán las claves de unión utilizadas para generar datos de entrenamiento. Las vistas de características contienen todas las características que necesita para el entrenamiento y la inferencia de su modelo. Tenemos entidades y vistas de características para este ejemplo definidas en nuestro [repositorio de código abierto](https://github.com/snowflakedb/snowflake-ml-python/tree/main/snowflake/ml/feature_store/examples). Cargaremos las definiciones con `load_entities()` y `load_draft_feature_views()` para simplificar."
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ebe57406-6834-428d-8772-8d7e1265b08b",
   "metadata": {
    "codeCollapsed": false,
    "collapsed": false,
    "language": "python",
    "name": "register_entities"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------------\n",
      "|\"NAME\"        |\"JOIN_KEYS\"       |\"DESC\"                 |\"OWNER\"   |\n",
      "----------------------------------------------------------------------\n",
      "|DOLOCATIONID  |[\"DOLOCATIONID\"]  |Drop off location id.  |ENGINEER  |\n",
      "|TRIP_ID       |[\"TRIP_ID\"]       |Trip id.               |ENGINEER  |\n",
      "----------------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "all_entities = []\n",
    "for e in example_helper.load_entities():\n",
    "    entity = fs.register_entity(e)\n",
    "    all_entities.append(entity)\n",
    "fs.list_entities().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "415e5e69-d605-4285-bb8b-e4d378cc35e9",
   "metadata": {
    "collapsed": false,
    "language": "python",
    "name": "register_feature_views"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------------------------------------------\n",
      "|\"NAME\"      |\"VERSION\"  |\"DESC\"                                              |\"REFRESH_FREQ\"  |\n",
      "------------------------------------------------------------------------------------------------\n",
      "|F_LOCATION  |1.0        |Features aggregated by location id and refreshe...  |12 hours        |\n",
      "|F_TRIP      |1.0        |Features per trip refreshed every day.              |1 day           |\n",
      "------------------------------------------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "all_feature_views = []\n",
    "for fv in example_helper.load_draft_feature_views():\n",
    "    rf = fs.register_feature_view(\n",
    "        feature_view=fv,\n",
    "        version='1.0'\n",
    "    )\n",
    "    all_feature_views.append(rf)\n",
    "\n",
    "fs.list_feature_views().select('name', 'version', 'desc', 'refresh_freq').show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c8daa62-4f51-4597-b8e5-812a0fc6f955",
   "metadata": {
    "name": "examine_features_md",
    "collapsed": false
   },
   "source": "Podemos examinar todas las características en una vista de características."
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9e8474a2-72c3-4c54-a4a3-7c3d97b7a9a4",
   "metadata": {
    "collapsed": false,
    "language": "python",
    "name": "examine_features"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F_LOCATION/1.0 has features:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Desc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AVG_FARE_1H</td>\n",
       "      <td>Averaged fare in past 1 hour window aggregated...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AVG_FARE_10H</td>\n",
       "      <td>Averaged fare in past 10 hours aggregated by l...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Name                                               Desc\n",
       "0   AVG_FARE_1H  Averaged fare in past 1 hour window aggregated...\n",
       "1  AVG_FARE_10H  Averaged fare in past 10 hours aggregated by l..."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F_TRIP/1.0 has features:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Desc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>PASSENGER_COUNT</td>\n",
       "      <td>The count of passenger of a trip.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>TRIP_DISTANCE</td>\n",
       "      <td>The distance of a trip.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>FARE_AMOUNT</td>\n",
       "      <td>The fare of a trip.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Name                               Desc\n",
       "0  PASSENGER_COUNT  The count of passenger of a trip.\n",
       "1    TRIP_DISTANCE            The distance of a trip.\n",
       "2      FARE_AMOUNT                The fare of a trip."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "for fv in all_feature_views:\n",
    "    print(f\"{fv.name}/{fv.version} has features:\")\n",
    "    pd.DataFrame(fv.feature_descs.items(), columns=['Name', 'Desc']).style"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1febc16-4aee-4fd1-a8a1-9bec833243cc",
   "metadata": {
    "collapsed": false,
    "name": "examine_features_ui_md"
   },
   "source": "### Examinar características en la UI de Snowflake\nAhora debería poder ver las entidades y vistas de características registradas en la UI de Snowflake."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31a3e252-5ebb-40a6-b8dc-d2ac248c1613",
   "metadata": {
    "collapsed": false,
    "language": "python",
    "name": "examine_features_ui"
   },
   "outputs": [],
   "source": "import streamlit as st\nst.image(\"https://raw.githubusercontent.com/Snowflake-Labs/sfguide-develop-and-manage-ml-models-with-feature-store-and-model-registry/refs/heads/main/notebooks/feature-store-ui.png\")"
  },
  {
   "cell_type": "markdown",
   "id": "c3f2908f-3033-4407-89e7-6761d32f8c19",
   "metadata": {
    "collapsed": false,
    "name": "generate_data_md"
   },
   "source": "## Generar Datos de Entrenamiento\n\nUna vez que nuestros pipelines de características estén completamente configurados, podemos usarlos para generar [Snowflake Dataset](https://docs.snowflake.com/en/developer-guide/snowpark-ml/dataset) y posteriormente realizar el entrenamiento del modelo. Generar datos de entrenamiento es fácil ya que las FeatureViews materializadas ya llevan la mayoría de los metadatos como claves de unión, marca de tiempo para búsquedas puntuales, etc. Solo necesitamos proporcionar los datos \"spine\" (se llama spine porque es la lista de IDs de entidad que estamos enriqueciendo esencialmente uniendo características con ellos).\n\n`generate_dataset()` devuelve un objeto Snowflake Dataset, que es óptimo para el entrenamiento distribuido con frameworks de aprendizaje profundo como TensorFlow o Pytorch que requieren acceso a nivel de archivo detallado. Crea un nuevo objeto Dataset (que está versionado e inmutable) en Snowflake que materializa los datos en archivos Parquet. Si entrena modelos con librerías clásicas de ML como Snowpark ML o scikit-learn, puede usar `generate_training_set()` que devuelve una tabla clásica de Snowflake. La celda siguiente demuestra `generate_dataset()`."
  },
  {
   "cell_type": "markdown",
   "id": "ec901a65-f3ee-4c12-b8ff-ec0f630e5372",
   "metadata": {
    "collapsed": false,
    "name": "retrieve_metadata_md"
   },
   "source": "Recuperar algunas columnas de metadatos que son esenciales al generar datos de entrenamiento."
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a6c80b76-99a4-4eb0-b0cb-583afa434ecf",
   "metadata": {
    "collapsed": false,
    "language": "python",
    "name": "retrieve_metadata"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "timestamp col: TPEP_PICKUP_DATETIME\n",
      "excluded cols: []\n",
      "label cols: ['TOTAL_AMOUNT']\n",
      "join keys: ['TRIP_ID', 'DOLOCATIONID']\n",
      "training spine table: \"AIRLINE_FEATURE_STORE\".SNOWFLAKE_FEATURE_STORE_NOTEBOOK_DEMO.nyc_yellow_trips\n"
     ]
    }
   ],
   "source": [
    "label_cols = example_helper.get_label_cols()\n",
    "timestamp_col = example_helper.get_training_data_timestamp_col()\n",
    "excluded_cols = example_helper.get_excluded_cols()\n",
    "join_keys = [key for entity in all_entities for key in entity.join_keys]\n",
    "spine_table = example_helper.get_training_spine_table()\n",
    "print(f'timestamp col: {timestamp_col}')\n",
    "print(f'excluded cols: {excluded_cols}')\n",
    "print(f'label cols: {label_cols}')\n",
    "print(f'join keys: {join_keys}')\n",
    "print(f'training spine table: {spine_table}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f66ad1d-5ad1-4ad8-92f9-c65be491e0c3",
   "metadata": {
    "name": "create_spline_md",
    "collapsed": false
   },
   "source": "Crear un dataframe spine que se muestree apartir de la tabla de origen."
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ea00fe3a-ac16-45d7-95c0-7ea7ed344e79",
   "metadata": {
    "language": "python",
    "name": "create_spline"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------------------\n",
      "|\"TOTAL_AMOUNT\"  |\"TRIP_ID\"  |\"DOLOCATIONID\"  |\"TPEP_PICKUP_DATETIME\"  |\n",
      "------------------------------------------------------------------------\n",
      "|11.8            |4391772    |236             |2016-01-13 15:28:31     |\n",
      "|6.8             |9640580    |231             |2016-01-28 21:47:03     |\n",
      "|10.3            |8986296    |162             |2016-01-27 06:44:50     |\n",
      "|20.35           |4689446    |261             |2016-01-14 09:29:27     |\n",
      "|19.89           |9360850    |166             |2016-01-28 07:33:07     |\n",
      "|6.3             |9335036    |211             |2016-01-28 04:46:46     |\n",
      "|72.92           |5223446    |264             |2016-01-15 17:21:27     |\n",
      "|16.3            |4578405    |116             |2016-01-13 23:35:00     |\n",
      "|7.3             |5045083    |163             |2016-01-15 07:10:06     |\n",
      "|10.3            |9733135    |145             |2016-01-29 05:14:06     |\n",
      "------------------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sample_count = 512\n",
    "source_df = session.sql(f\"\"\"\n",
    "    select {','.join(label_cols)}, \n",
    "            {','.join(join_keys)} \n",
    "            {',' + timestamp_col if timestamp_col is not None else ''} \n",
    "    from {spine_table}\n",
    "\"\"\")\n",
    "spine_df = source_df.sample(n=sample_count)\n",
    "# preview spine dataframe\n",
    "spine_df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35b8b59a-dcae-41a4-8954-db6719c5cf60",
   "metadata": {
    "name": "generate_dataset_md",
    "collapsed": false
   },
   "source": "Generar objeto dataset a partir del dataframe spine y las vistas de características."
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5e85993d-3b1a-41d5-af13-96b7c2716e74",
   "metadata": {
    "language": "python",
    "name": "generate_dataset"
   },
   "outputs": [],
   "source": [
    "my_dataset = fs.generate_dataset(\n",
    "    name=\"my_cool_training_dataset\",\n",
    "    spine_df=spine_df, \n",
    "    features=all_feature_views,\n",
    "    version=\"4.0\",\n",
    "    spine_timestamp_col=timestamp_col,\n",
    "    spine_label_cols=label_cols,\n",
    "    exclude_columns=excluded_cols,\n",
    "    desc=\"This is the dataset joined spine dataframe with feature views\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a1cf2f4-59b3-40da-8c43-bee27129105d",
   "metadata": {
    "name": "view_dataset_md",
    "collapsed": false
   },
   "source": "Convierta el dataset a un dataframe de Snowpark y examine todas las características en él."
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5f3c71aa-1c6b-4bf4-83f9-2176dc249f83",
   "metadata": {
    "language": "python",
    "name": "view_dataset"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TOTAL_AMOUNT</th>\n",
       "      <th>TRIP_ID</th>\n",
       "      <th>DOLOCATIONID</th>\n",
       "      <th>TPEP_PICKUP_DATETIME</th>\n",
       "      <th>AVG_FARE_1H</th>\n",
       "      <th>AVG_FARE_10H</th>\n",
       "      <th>PASSENGER_COUNT</th>\n",
       "      <th>TRIP_DISTANCE</th>\n",
       "      <th>FARE_AMOUNT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6.300000</td>\n",
       "      <td>9753533</td>\n",
       "      <td>228</td>\n",
       "      <td>2016-01-29 07:50:17-08:00</td>\n",
       "      <td>42.083332</td>\n",
       "      <td>25.560465</td>\n",
       "      <td>1</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>5.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-4.800000</td>\n",
       "      <td>337386</td>\n",
       "      <td>161</td>\n",
       "      <td>2016-01-01 23:27:54-08:00</td>\n",
       "      <td>9.713513</td>\n",
       "      <td>10.708535</td>\n",
       "      <td>2</td>\n",
       "      <td>0.150000</td>\n",
       "      <td>-3.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>12.250000</td>\n",
       "      <td>521354</td>\n",
       "      <td>161</td>\n",
       "      <td>2016-01-02 16:00:37-08:00</td>\n",
       "      <td>10.513055</td>\n",
       "      <td>9.510478</td>\n",
       "      <td>3</td>\n",
       "      <td>1.110000</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>18.799999</td>\n",
       "      <td>536727</td>\n",
       "      <td>161</td>\n",
       "      <td>2016-01-02 17:30:49-08:00</td>\n",
       "      <td>11.397975</td>\n",
       "      <td>9.790948</td>\n",
       "      <td>5</td>\n",
       "      <td>2.500000</td>\n",
       "      <td>16.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>15.300000</td>\n",
       "      <td>1059372</td>\n",
       "      <td>161</td>\n",
       "      <td>2016-01-04 11:12:42-08:00</td>\n",
       "      <td>10.893401</td>\n",
       "      <td>9.468452</td>\n",
       "      <td>1</td>\n",
       "      <td>2.500000</td>\n",
       "      <td>12.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>507</th>\n",
       "      <td>38.299999</td>\n",
       "      <td>371165</td>\n",
       "      <td>244</td>\n",
       "      <td>2016-01-02 02:56:18-08:00</td>\n",
       "      <td>23.259615</td>\n",
       "      <td>22.674618</td>\n",
       "      <td>1</td>\n",
       "      <td>13.300000</td>\n",
       "      <td>37.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>508</th>\n",
       "      <td>21.799999</td>\n",
       "      <td>4212437</td>\n",
       "      <td>244</td>\n",
       "      <td>2016-01-13 04:03:58-08:00</td>\n",
       "      <td>22.120001</td>\n",
       "      <td>22.395477</td>\n",
       "      <td>1</td>\n",
       "      <td>7.170000</td>\n",
       "      <td>20.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>509</th>\n",
       "      <td>42.349998</td>\n",
       "      <td>7530490</td>\n",
       "      <td>244</td>\n",
       "      <td>2016-01-21 17:51:06-08:00</td>\n",
       "      <td>25.574074</td>\n",
       "      <td>23.103773</td>\n",
       "      <td>1</td>\n",
       "      <td>7.900000</td>\n",
       "      <td>33.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>510</th>\n",
       "      <td>14.300000</td>\n",
       "      <td>7304440</td>\n",
       "      <td>4</td>\n",
       "      <td>2016-01-21 03:12:42-08:00</td>\n",
       "      <td>8.818182</td>\n",
       "      <td>10.719931</td>\n",
       "      <td>1</td>\n",
       "      <td>2.680000</td>\n",
       "      <td>12.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>511</th>\n",
       "      <td>66.949997</td>\n",
       "      <td>10352420</td>\n",
       "      <td>97</td>\n",
       "      <td>2016-01-30 16:03:07-08:00</td>\n",
       "      <td>17.518518</td>\n",
       "      <td>15.804812</td>\n",
       "      <td>2</td>\n",
       "      <td>20.299999</td>\n",
       "      <td>55.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>512 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     TOTAL_AMOUNT   TRIP_ID  DOLOCATIONID      TPEP_PICKUP_DATETIME  \\\n",
       "0        6.300000   9753533           228 2016-01-29 07:50:17-08:00   \n",
       "1       -4.800000    337386           161 2016-01-01 23:27:54-08:00   \n",
       "2       12.250000    521354           161 2016-01-02 16:00:37-08:00   \n",
       "3       18.799999    536727           161 2016-01-02 17:30:49-08:00   \n",
       "4       15.300000   1059372           161 2016-01-04 11:12:42-08:00   \n",
       "..            ...       ...           ...                       ...   \n",
       "507     38.299999    371165           244 2016-01-02 02:56:18-08:00   \n",
       "508     21.799999   4212437           244 2016-01-13 04:03:58-08:00   \n",
       "509     42.349998   7530490           244 2016-01-21 17:51:06-08:00   \n",
       "510     14.300000   7304440             4 2016-01-21 03:12:42-08:00   \n",
       "511     66.949997  10352420            97 2016-01-30 16:03:07-08:00   \n",
       "\n",
       "     AVG_FARE_1H  AVG_FARE_10H  PASSENGER_COUNT  TRIP_DISTANCE  FARE_AMOUNT  \n",
       "0      42.083332     25.560465                1       0.800000          5.5  \n",
       "1       9.713513     10.708535                2       0.150000         -3.5  \n",
       "2      10.513055      9.510478                3       1.110000          9.0  \n",
       "3      11.397975      9.790948                5       2.500000         16.0  \n",
       "4      10.893401      9.468452                1       2.500000         12.5  \n",
       "..           ...           ...              ...            ...          ...  \n",
       "507    23.259615     22.674618                1      13.300000         37.0  \n",
       "508    22.120001     22.395477                1       7.170000         20.5  \n",
       "509    25.574074     23.103773                1       7.900000         33.5  \n",
       "510     8.818182     10.719931                1       2.680000         12.0  \n",
       "511    17.518518     15.804812                2      20.299999         55.0  \n",
       "\n",
       "[512 rows x 9 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_data_df = my_dataset.read.to_snowpark_dataframe()\n",
    "assert training_data_df.count() == sample_count\n",
    "# drop rows that have any nulls in value. \n",
    "training_data_df = training_data_df.dropna(how='any')\n",
    "training_data_df.to_pandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1da355bc-08f3-4052-8c9c-b5a9458677a8",
   "metadata": {
    "collapsed": false,
    "name": "train_model_md"
   },
   "source": "## Entrenar modelo con Snowpark ML\n\nAhora entrenemos un modelo simple de random forest y evaluemos la precisión de la predicción. Cuando llama a fit() en un DataFrame que se crea a partir de un Dataset, la vinculación entre el modelo entrenado y el dataset se configura automáticamente."
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "91d355cb-9b5b-4aca-92ec-16cfe67118db",
   "metadata": {
    "codeCollapsed": false,
    "language": "python",
    "name": "train_model"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "feature cols: ['TRIP_DISTANCE', 'FARE_AMOUNT', 'AVG_FARE_10H', 'PASSENGER_COUNT', 'AVG_FARE_1H']\n",
      "MSE: 8.587654420611477, Accuracy: 99.83667856616516\n"
     ]
    }
   ],
   "source": [
    "from snowflake.ml.modeling.ensemble import RandomForestRegressor\n",
    "from snowflake.ml.modeling import metrics as snowml_metrics\n",
    "from snowflake.snowpark.functions import abs as sp_abs, mean, col\n",
    "\n",
    "def train_model_using_snowpark_ml(training_data_df):\n",
    "    train, test = training_data_df.random_split([0.8, 0.2], seed=42)\n",
    "    feature_columns = list(set(training_data_df.columns) - set(label_cols) - set(join_keys) - set([timestamp_col]))\n",
    "    print(f\"feature cols: {feature_columns}\")\n",
    "    \n",
    "    rf = RandomForestRegressor(\n",
    "        input_cols=feature_columns, label_cols=label_cols, \n",
    "        max_depth=3, n_estimators=20, random_state=42\n",
    "    )\n",
    "\n",
    "    rf.fit(train)\n",
    "    predictions = rf.predict(test)\n",
    "\n",
    "    output_label_names = ['OUTPUT_' + col for col in label_cols]\n",
    "    mse = snowml_metrics.mean_squared_error(\n",
    "        df=predictions, \n",
    "        y_true_col_names=label_cols, \n",
    "        y_pred_col_names=output_label_names\n",
    "    )\n",
    "\n",
    "    accuracy = 100 - snowml_metrics.mean_absolute_percentage_error(\n",
    "        df=predictions,\n",
    "        y_true_col_names=label_cols,\n",
    "        y_pred_col_names=output_label_names\n",
    "    )\n",
    "\n",
    "    print(f\"MSE: {mse}, Accuracy: {accuracy}\")\n",
    "    return rf\n",
    "\n",
    "random_forest_model = train_model_using_snowpark_ml(training_data_df) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28b12493-3339-4369-82d4-46a4389f6bf1",
   "metadata": {
    "collapsed": false,
    "name": "model_registry_md"
   },
   "source": "## Registrar modelo en Model Registry\n\nDespués de entrenar el modelo, podemos guardarlo en Model Registry para poder administrar el modelo, sus metadatos incluyendo métricas, versiones, y usarlo posteriormente para inferencia."
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cf1209a6-4c8c-4441-9c5d-7688f4ec0233",
   "metadata": {
    "codeCollapsed": false,
    "language": "python",
    "name": "create_registry"
   },
   "outputs": [],
   "source": [
    "from snowflake.ml.registry import Registry\n",
    "\n",
    "registry = Registry(\n",
    "    session=session, \n",
    "    database_name=session.get_current_database(), \n",
    "    schema_name=MODEL_DEMO_SCHEMA,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94bcf485-9c9a-4a74-a8a2-3154c8f5aa74",
   "metadata": {
    "name": "log_model_md",
    "collapsed": false
   },
   "source": "Registrar modelo en Model Registry."
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ded2ec74-fd46-445d-8fe9-1b133e4284eb",
   "metadata": {
    "language": "python",
    "name": "log_model"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/wezhou/miniconda3/envs/py38/lib/python3.8/contextlib.py:113: UserWarning: `relax_version` is not set and therefore defaulted to True. Dependency version constraints relaxed from ==x.y.z to >=x.y, <(x+1). To use specific dependency versions for compatibility, reproducibility, etc., set `options={'relax_version': False}` when logging the model.\n",
      "  return next(self.gen)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ModelVersion(\n",
       "  name='MY_RANDOM_FOREST_REGRESSOR_MODEL',\n",
       "  version='V1',\n",
       ")"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_name = \"MY_RANDOM_FOREST_REGRESSOR_MODEL\"\n",
    "\n",
    "registry.log_model(\n",
    "    model_name=model_name,\n",
    "    version_name=\"v1\",\n",
    "    model=random_forest_model,\n",
    "    comment=\"My model trained with feature views, dataset\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d7eaf0c-a31b-40e0-acdd-1dc4fb9ecb4f",
   "metadata": {
    "collapsed": false,
    "name": "model_registry_ui_md"
   },
   "source": "### Examinar modelo en la UI de Snowflake\nAhora debería poder ver el modelo en la UI de Snowflake."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a741958a-58f5-4e30-9859-760a3a260ca0",
   "metadata": {
    "language": "python",
    "name": "model_registry_img"
   },
   "outputs": [],
   "source": "import streamlit as st\nst.image(\"https://raw.githubusercontent.com/Snowflake-Labs/sfguide-develop-and-manage-ml-models-with-feature-store-and-model-registry/refs/heads/main/notebooks/model-registry-ui.png\")"
  },
  {
   "cell_type": "markdown",
   "id": "1387a446-4a7e-4347-9f41-01b56d1cd39a",
   "metadata": {
    "collapsed": false,
    "name": "predict_md"
   },
   "source": "## Predecir con el modelo\n\n¡Finalmente, estamos casi listos para la predicción! Para esto, podemos buscar los valores de características más recientes en Feature Store para los registros de datos específicos sobre los que estamos ejecutando la predicción. Uno de los beneficios clave de usar Feature Store es que proporciona una forma de servir automáticamente los valores de características correctos durante la predicción con valores de características correctos en un punto en el tiempo. `load_feature_views_from_dataset()` obtiene las mismas vistas de características utilizadas en el entrenamiento, luego `retrieve_feature_values()` busca los valores de características más recientes."
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "df2f001a-732a-4c0b-b02d-b3cdab5422ee",
   "metadata": {
    "language": "python",
    "name": "test_dataset"
   },
   "outputs": [],
   "source": [
    "test_df = source_df.sample(n=3)\n",
    "\n",
    "# load back feature views from dataset\n",
    "fvs = fs.load_feature_views_from_dataset(my_dataset)\n",
    "enriched_df = fs.retrieve_feature_values(\n",
    "    test_df, \n",
    "    features=fvs,\n",
    "    exclude_columns=join_keys,\n",
    "    spine_timestamp_col=timestamp_col\n",
    ")\n",
    "enriched_df = enriched_df.drop(join_keys)\n",
    "enriched_pd = enriched_df.to_pandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7db2f69f-1597-4f43-9b59-554c48112a47",
   "metadata": {
    "collapsed": false,
    "name": "predict_local_md"
   },
   "source": "### [Opcional 1] predecir con modelo local\nAhora podemos predecir con un modelo local y los valores de características recuperados de feature store."
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6307ba80-532e-4b5f-90f6-8b162e740702",
   "metadata": {
    "language": "python",
    "name": "predict_local"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   TOTAL_AMOUNT TPEP_PICKUP_DATETIME  AVG_FARE_1H  AVG_FARE_10H  \\\n",
      "0         15.96  2016-01-07 10:26:02     9.440415      9.324965   \n",
      "1         10.55  2016-01-01 18:44:40    10.083333      9.236685   \n",
      "2         17.80  2016-01-29 21:05:54    10.385390     10.287410   \n",
      "\n",
      "   PASSENGER_COUNT  TRIP_DISTANCE  FARE_AMOUNT  OUTPUT_TOTAL_AMOUNT  \n",
      "0                1           2.23         12.5            16.440312  \n",
      "1                1           1.70          7.0             8.523669  \n",
      "2                1           3.11         16.5            18.717726  \n"
     ]
    }
   ],
   "source": [
    "pred = random_forest_model.predict(enriched_pd)\n",
    "print(pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04ff6c72-77f8-4aee-aa76-dba0d0e70cd9",
   "metadata": {
    "collapsed": false,
    "name": "predict_reigstry_md"
   },
   "source": "### [Opción 2] Predecir con Model Registry\n\nTambién podemos recuperar el modelo de model registry y ejecutar predicciones sobre el modelo utilizando los valores de características más recientes."
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "efd0ef2d-2d4f-4dfd-a6c5-3eee960ea5a0",
   "metadata": {
    "codeCollapsed": false,
    "language": "python",
    "name": "predict_registry"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   TRIP_DISTANCE  FARE_AMOUNT  AVG_FARE_10H  PASSENGER_COUNT  AVG_FARE_1H  \\\n",
      "0           2.23         12.5      9.324965                1     9.440415   \n",
      "1           1.70          7.0      9.236685                1    10.083333   \n",
      "2           3.11         16.5     10.287410                1    10.385390   \n",
      "\n",
      "   OUTPUT_TOTAL_AMOUNT  \n",
      "0            16.440312  \n",
      "1             8.523669  \n",
      "2            18.717726  \n"
     ]
    }
   ],
   "source": [
    "# model is retrieved from Model Registry\n",
    "model = registry.get_model(model_name).version(\"v1\")\n",
    "restored_prediction = model.run(enriched_pd, function_name=\"predict\")\n",
    "print(restored_prediction)"
   ]
  }
 ]
}
