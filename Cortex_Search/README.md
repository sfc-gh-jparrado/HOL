# RAG con Snowflake Cortex Search - Gu√≠a en Espa√±ol

## Descripci√≥n General

En este quickstart te mostraremos c√≥mo construir de forma r√°pida y segura una aplicaci√≥n RAG (Retrieval Augmented Generation) full-stack en Snowflake sin tener que construir integraciones, gestionar infraestructura o lidiar con preocupaciones de seguridad relacionadas con datos que se mueven fuera del marco de gobernanza de Snowflake.

Esta gu√≠a aprovecha **Cortex Search**, un servicio completamente gestionado que crea autom√°ticamente embeddings para tus datos y realiza recuperaciones usando un motor de b√∫squeda h√≠brido, combinando embeddings para similitud sem√°ntica m√°s b√∫squeda por palabras clave para similitud l√©xica, logrando una calidad de recuperaci√≥n de √∫ltima generaci√≥n.

## ¬øQu√© es RAG?

**Retrieval Augmented Generation (RAG)** es una t√©cnica que combina:
1. **Recuperaci√≥n**: Buscar informaci√≥n relevante en un corpus de documentos
2. **Generaci√≥n**: Usar un LLM para generar respuestas basadas en esa informaci√≥n

RAG permite que los modelos de lenguaje respondan preguntas sobre datos espec√≠ficos de tu organizaci√≥n, manteniendo las respuestas fundamentadas en hechos reales.

## ¬øPor Qu√© Snowflake Cortex Search?

**Cortex Search** simplifica dram√°ticamente la construcci√≥n de aplicaciones RAG al:
- ‚úÖ Crear y gestionar embeddings autom√°ticamente
- ‚úÖ Usar b√∫squeda h√≠brida (sem√°ntica + l√©xica) para mejor recuperaci√≥n
- ‚úÖ Mantenerse actualizado autom√°ticamente con tus datos
- ‚úÖ Eliminar la necesidad de infraestructura externa de vectores
- ‚úÖ Mantener todo dentro de Snowflake (seguridad y gobernanza)

## Contenido del Repositorio

```
Cortex_Search/
‚îÇ
‚îú‚îÄ‚îÄ README.md                                  # Este archivo
‚îú‚îÄ‚îÄ RAG_Usando_Snowflake_Cortex_Search.ipynb  # Notebook de Snowflake con todo el proceso
‚îÇ
‚îî‚îÄ‚îÄ documentos/                                # Documentos PDF originales (en ingl√©s)
    ‚îú‚îÄ‚îÄ Carver Skis Specification Guide.pdf
    ‚îú‚îÄ‚îÄ RacingFast Skis Specification Guide.pdf
    ‚îú‚îÄ‚îÄ OutPiste Skis Specification Guide.pdf
    ‚îú‚îÄ‚îÄ Premium_Bicycle_User_Guide.pdf
    ‚îú‚îÄ‚îÄ The_Xtreme_Road_Bike_105_SL.pdf
    ‚îú‚îÄ‚îÄ The_Ultimate_Downhill_Bike.pdf
    ‚îú‚îÄ‚îÄ Mondracer_Infant_Bike.pdf
    ‚îî‚îÄ‚îÄ Ski_Boots_TDBootz_Special.pdf
```

## Prerrequisitos

### Cuenta de Snowflake
- Una cuenta activa de Snowflake
- Rol con permisos para:
  - Crear bases de datos, schemas y tablas
  - Crear stages
  - Crear servicios de Cortex Search
  - Crear stored procedures y tasks
  - Usar funciones de Snowflake Cortex (PARSE_DOCUMENT, CLASSIFY_TEXT, etc.)

### Warehouse
- Un warehouse compute (peque√±o es suficiente para este ejemplo)
- El warehouse debe estar activo o puedes usar `COMPUTE_WH` (por defecto)

### Conocimientos
- SQL b√°sico
- Conceptos b√°sicos de RAG (recomendado pero no obligatorio)
- Familiaridad con Snowflake (recomendado)

## Instalaci√≥n R√°pida

### Paso 1: Configurar Base de Datos

```sql
-- Crear base de datos y schema
CREATE DATABASE IF NOT EXISTS CC_QUICKSTART_CORTEX_SEARCH_DOCS;
USE DATABASE CC_QUICKSTART_CORTEX_SEARCH_DOCS;

CREATE SCHEMA IF NOT EXISTS DATA;
USE SCHEMA DATA;

-- Usar el warehouse
USE WAREHOUSE COMPUTE_WH;  -- Cambia por tu warehouse
```

### Paso 2: Crear Stage y Subir Documentos

```sql
-- Crear stage con cifrado y tabla de directorio habilitada
CREATE OR REPLACE STAGE docs 
ENCRYPTION = (TYPE = 'SNOWFLAKE_SSE') 
DIRECTORY = (ENABLE = true);
```

**Subir documentos manualmente:**
1. Ve a **Data** en el men√∫ izquierdo de Snowflake
2. Selecciona tu base de datos `CC_QUICKSTART_CORTEX_SEARCH_DOCS`
3. Selecciona tu schema `DATA`
4. Haz clic en **Stages** y luego en `DOCS`
5. Haz clic en el bot√≥n **+Files** (arriba a la derecha)
6. Arrastra y suelta los archivos `.txt` de la carpeta `documentos/`

**O usar SnowSQL:**
```bash
snowsql -c my_connection
```

```sql
PUT file:///ruta/a/documentos/*.pdf @docs AUTO_COMPRESS=FALSE;
```

**O usar Python:**
```python
from snowflake.snowpark import Session
import glob

session = Session.builder.configs({...}).create()

# Subir todos los PDFs
for pdf_file in glob.glob("documentos/*.pdf"):
    session.file.put(pdf_file, "@docs", auto_compress=False)
```

### Paso 3: Verificar Archivos Subidos

```sql
-- Listar archivos en el stage
LS @docs;
```

Deber√≠as ver 8 archivos PDF listados.

### Paso 4: Ejecutar el Notebook

Opci√≥n 1: **Notebook de Snowflake (Recomendado)**
1. Ve a **Projects** > **Notebooks** en Snowflake
2. Haz clic en **+ Notebook**
3. Importa el archivo `RAG_Usando_Snowflake_Cortex_Search.ipynb`
4. Ejecuta cada celda secuencialmente

Opci√≥n 2: **Ejecutar SQL Manualmente**
- Copia y pega el c√≥digo SQL del notebook en un worksheet de Snowflake
- Ejecuta cada bloque en orden

## Gu√≠a Paso a Paso

### 1. Procesamiento de Documentos

#### 1.1. Extraer Texto de Documentos PDF

Snowflake puede procesar documentos PDF usando la funci√≥n `PARSE_DOCUMENT`. Esta funci√≥n soporta PDF, DOCX, PPTX, TXT, HTML, XML, Markdown y otros formatos:

```sql
CREATE OR REPLACE TEMPORARY TABLE RAW_TEXT AS
SELECT 
    RELATIVE_PATH,
    SIZE,
    FILE_URL,
    BUILD_SCOPED_FILE_URL(@docs, relative_path) AS SCOPED_FILE_URL,
    TO_VARCHAR (
        SNOWFLAKE.CORTEX.PARSE_DOCUMENT (
            '@docs',
            RELATIVE_PATH,
            {'mode': 'LAYOUT'}
        ):content
    ) AS EXTRACTED_LAYOUT 
FROM 
    DIRECTORY('@docs');
```

**¬øQu√© hace esto?**
- `PARSE_DOCUMENT`: Extrae texto de archivos PDF manteniendo la estructura
- `mode: LAYOUT`: Preserva el layout del documento incluyendo tablas, columnas, formato
- `DIRECTORY`: Lee metadata de archivos del stage (nombre, tama√±o, URL)
- El texto extra√≠do mantiene el formato original del PDF

#### 1.2. Crear Tabla para Chunks

```sql
CREATE OR REPLACE TABLE DOCS_CHUNKS_TABLE ( 
    RELATIVE_PATH STRING,
    SIZE NUMBER(38,0),
    FILE_URL STRING,
    SCOPED_FILE_URL STRING,
    CHUNK STRING,          -- El fragmento de texto
    CHUNK_INDEX INTEGER,   -- Posici√≥n del fragmento
    CATEGORY STRING        -- Categor√≠a del documento
);
```

#### 1.3. Fragmentar Documentos (Chunking)

```sql
INSERT INTO DOCS_CHUNKS_TABLE (relative_path, size, file_url,
                            scoped_file_url, chunk, chunk_index)
SELECT 
    relative_path, 
    size,
    file_url, 
    scoped_file_url,
    c.value::TEXT AS chunk,
    c.INDEX::INTEGER AS chunk_index
FROM 
    RAW_TEXT,
    LATERAL FLATTEN(
        input => SNOWFLAKE.CORTEX.SPLIT_TEXT_RECURSIVE_CHARACTER (
            EXTRACTED_LAYOUT,
            'markdown',
            1512,  -- Tama√±o m√°ximo del chunk
            256,   -- Overlap entre chunks
            ['\n\n', '\n', ' ', '']  -- Separadores
        )
    ) c;
```

**Par√°metros de Chunking:**
- **Tama√±o del chunk (1512)**: Cada fragmento tendr√° m√°ximo ~1512 caracteres
- **Overlap (256)**: Habr√° 256 caracteres de solapamiento entre chunks consecutivos
- **Separadores**: Define d√≥nde cortar el texto (p√°rrafos, l√≠neas, espacios)

**¬øPor qu√© chunking?**
- Los LLMs tienen l√≠mites de tokens
- Chunks m√°s peque√±os = b√∫squedas m√°s precisas
- El overlap asegura que no se pierda contexto en los l√≠mites

### 2. Clasificaci√≥n Autom√°tica de Documentos

```sql
CREATE OR REPLACE TEMPORARY TABLE docs_categories AS 
WITH unique_documents AS (
    SELECT
        DISTINCT relative_path, 
        chunk
    FROM
        docs_chunks_table
    WHERE 
        chunk_index = 0  -- Solo el primer chunk
),
docs_category_cte AS (
    SELECT
        relative_path,
        TRIM(
            SNOWFLAKE.CORTEX.CLASSIFY_TEXT (
                'T√≠tulo:' || relative_path || ' Contenido:' || chunk, 
                ['Bicicleta', 'Esqu√≠']  -- Categor√≠as posibles
            )['label'], 
            '"'
        ) AS category
    FROM
        unique_documents
)
SELECT * FROM docs_category_cte;
```

**¬øQu√© hace CLASSIFY_TEXT?**
- Usa un LLM para clasificar documentos autom√°ticamente
- Le pasas el texto y las categor√≠as posibles
- Devuelve la categor√≠a m√°s probable

**Actualizar tabla con categor√≠as:**

```sql
UPDATE docs_chunks_table 
SET category = docs_categories.category
FROM docs_categories
WHERE docs_chunks_table.relative_path = docs_categories.relative_path;
```

### 3. Crear Servicio Cortex Search

Este es el paso clave:

```sql
CREATE OR REPLACE CORTEX SEARCH SERVICE CC_SEARCH_SERVICE_CS
ON chunk                 -- Columna para crear embeddings
ATTRIBUTES category      -- Columnas para filtrado
WAREHOUSE = COMPUTE_WH   -- Warehouse para mantenimiento
TARGET_LAG = '1 minute'  -- Frecuencia de actualizaci√≥n
AS (
    SELECT 
        chunk,
        chunk_index,
        relative_path,
        file_url,
        category
    FROM docs_chunks_table
);
```

**Componentes del Servicio:**
- **ON chunk**: Cortex Search crear√° embeddings del campo `chunk` autom√°ticamente
- **ATTRIBUTES category**: Campos que pueden usarse para filtrar b√∫squedas
- **TARGET_LAG**: Qu√© tan frecuentemente se actualiza el √≠ndice
- **WAREHOUSE**: Qu√© warehouse usar para mantenimiento (usa cr√©ditos)

**¬øQu√© sucede internamente?**
1. Cortex Search lee todos los chunks
2. Crea embeddings usando modelos de Snowflake
3. Crea un √≠ndice h√≠brido (sem√°ntico + l√©xico)
4. Mantiene el √≠ndice actualizado autom√°ticamente

### 4. Consultar el Servicio

#### Consulta B√°sica

```sql
SELECT 
    chunk,
    relative_path,
    category
FROM TABLE(
    CC_SEARCH_SERVICE_CS.SEARCH(
        '¬øcu√°les son las especificaciones de las bicicletas de carretera?',
        10  -- Top 10 resultados
    )
);
```

#### Consulta con Filtro

```sql
SELECT 
    chunk,
    relative_path,
    category
FROM TABLE(
    CC_SEARCH_SERVICE_CS.SEARCH(
        '¬øqu√© productos de esqu√≠ est√°n disponibles?',
        10,
        {'category': 'Esqu√≠'}  -- Filtrar solo categor√≠a Esqu√≠
    )
);
```

**Tipos de B√∫squeda:**
- **Sem√°ntica**: Encuentra chunks con significado similar (usa embeddings)
- **L√©xica**: Encuentra chunks con palabras clave espec√≠ficas
- **H√≠brida**: Combina ambas para mejor precisi√≥n

### 5. Usar RAG con Cortex LLM

Ahora podemos combinar la b√∫squeda con un LLM para generar respuestas:

```sql
-- Paso 1: Buscar contexto relevante
WITH search_results AS (
    SELECT chunk
    FROM TABLE(
        CC_SEARCH_SERVICE_CS.SEARCH(
            '¬øcu√°les son las diferencias entre las bicicletas de carretera y las de monta√±a?',
            5
        )
    )
),
-- Paso 2: Concatenar contexto
context_string AS (
    SELECT LISTAGG(chunk, '\n\n') AS context
    FROM search_results
)
-- Paso 3: Generar respuesta con LLM
SELECT 
    SNOWFLAKE.CORTEX.COMPLETE(
        'mixtral-8x7b',
        CONCAT(
            'Bas√°ndote en el siguiente contexto, responde la pregunta del usuario.\n\n',
            'Contexto:\n',
            context,
            '\n\nPregunta: ¬øcu√°les son las diferencias entre las bicicletas de carretera y las de monta√±a?\n\n',
            'Respuesta:'
        )
    ) AS respuesta
FROM context_string;
```

**Flujo RAG:**
1. **Retrieve**: Buscar chunks relevantes con Cortex Search
2. **Augment**: Agregar ese contexto al prompt
3. **Generate**: Pedir al LLM que genere respuesta basada en el contexto

## Mantenimiento Autom√°tico

### Detectar Cambios con Streams

Streams de Snowflake capturan cambios (inserts, updates, deletes) en tablas o stages:

```sql
CREATE OR REPLACE STREAM insert_docs_stream ON STAGE docs;
CREATE OR REPLACE STREAM delete_docs_stream ON STAGE docs;
```

### Procesar Cambios con Stored Procedure

El stored procedure `insert_delete_docs_sp()` procesa autom√°ticamente:
- Nuevos archivos agregados al stage
- Archivos eliminados del stage
- Actualiza la tabla de chunks
- Reclasifica nuevos documentos

Ver notebook para c√≥digo completo.

### Automatizar con Tasks

```sql
CREATE OR REPLACE TASK insert_delete_docs_task
    WAREHOUSE = COMPUTE_WH
    SCHEDULE = '5 minute'
    WHEN SYSTEM$STREAM_HAS_DATA('delete_docs_stream')
AS
    CALL insert_delete_docs_sp();

ALTER TASK insert_delete_docs_task RESUME;
```

**¬øC√≥mo funciona?**
1. Task se ejecuta cada 5 minutos
2. Verifica si hay cambios en el stream
3. Si hay cambios, ejecuta el stored procedure
4. El stored procedure actualiza la tabla
5. Cortex Search detecta los cambios y actualiza el √≠ndice autom√°ticamente

## Aplicaci√≥n Streamlit (Opcional)

Para crear una interfaz de chat, puedes usar Streamlit en Snowflake. C√≥digo de ejemplo:

```python
import streamlit as st
import snowflake.snowpark as snowpark

# T√≠tulo
st.title("ü§ñ Asistente RAG con Cortex Search")

# Input del usuario
question = st.text_input("Haz una pregunta sobre los documentos:")

if question:
    # Buscar contexto
    search_query = f"""
    SELECT chunk
    FROM TABLE(
        CC_SEARCH_SERVICE_CS.SEARCH('{question}', 5)
    )
    """
    
    results = session.sql(search_query).collect()
    context = "\n\n".join([row['CHUNK'] for row in results])
    
    # Generar respuesta
    llm_query = f"""
    SELECT SNOWFLAKE.CORTEX.COMPLETE(
        'mixtral-8x7b',
        'Contexto: {context}\\n\\nPregunta: {question}\\n\\nRespuesta:'
    ) AS respuesta
    """
    
    response = session.sql(llm_query).collect()[0]['RESPUESTA']
    st.write(response)
```

## Mejores Pr√°cticas

### Chunking
- **Tama√±o √≥ptimo**: 512-2048 caracteres dependiendo del tipo de documento
- **Overlap**: 10-20% del tama√±o del chunk
- **Separadores**: Usar separadores sem√°nticos (p√°rrafos, secciones)

### B√∫squeda
- **N√∫mero de resultados**: 3-10 chunks t√≠picamente
- **Filtros**: Usar `ATTRIBUTES` para filtrar por categor√≠a, fecha, etc.
- **Reranking**: Considerar reordenar resultados con scoring adicional

### LLM
- **Modelos disponibles**: `mixtral-8x7b`, `llama2-70b-chat`, `mistral-large`, etc.
- **Prompt engineering**: Ser espec√≠fico sobre formato de respuesta deseado
- **L√≠mites de contexto**: Vigilar el tama√±o total del prompt

### Costos
- **Cortex Search**: Cobra por GB almacenado y queries ejecutadas
- **Cortex LLM**: Cobra por tokens generados
- **Warehouse**: Cobra por tiempo de compute activo
- **Storage**: Cobra por GB almacenado

## Casos de Uso

Esta arquitectura RAG es ideal para:

- üìö **Knowledge Bases**: Responder preguntas sobre documentaci√≥n interna
- üè¢ **Soporte al Cliente**: Asistentes que consultan manuales de producto
- üìã **An√°lisis de Contratos**: Extraer informaci√≥n de contratos legales
- üî¨ **Investigaci√≥n**: Buscar informaci√≥n en papers cient√≠ficos
- üíº **Due Diligence**: Analizar documentos financieros
- üìä **Reportes**: Generar res√∫menes de documentos complejos

## Soluci√≥n de Problemas

### Error: "Cortex Search service not found"
- Verifica que creaste el servicio correctamente
- Aseg√∫rate de estar en el database y schema correcto
- Revisa que el nombre del servicio sea exacto (case-sensitive)

### Error: "Permission denied"
- Tu rol necesita permisos para usar Cortex features
- Contacta a tu administrador de Snowflake

### Los resultados no son relevantes
- Revisa el chunking (quiz√°s los chunks son muy grandes/peque√±os)
- Prueba ajustar los separadores en `SPLIT_TEXT_RECURSIVE_CHARACTER`
- Considera agregar m√°s contexto en los prompts del LLM

### La task no se ejecuta
- Verifica que la task est√© RESUMED: `ALTER TASK insert_delete_docs_task RESUME;`
- Revisa los logs: `SELECT * FROM TABLE(INFORMATION_SCHEMA.TASK_HISTORY())`
- Aseg√∫rate de que el warehouse est√© disponible

## Recursos Adicionales

### Documentaci√≥n Oficial de Snowflake
- [Cortex Search](https://docs.snowflake.com/en/user-guide/snowflake-cortex/cortex-search)
- [Cortex LLM Functions](https://docs.snowflake.com/en/user-guide/snowflake-cortex/llm-functions)
- [Parse Document](https://docs.snowflake.com/en/sql-reference/functions/parse_document)
- [Classify Text](https://docs.snowflake.com/en/sql-reference/functions/classify_text-snowflake-cortex)

### Tutoriales y Quickstarts
- [Official Cortex Search Quickstart](https://quickstarts.snowflake.com/guide/ask_questions_to_your_own_documents_with_snowflake_cortex_search/)
- [RAG with Snowflake Cortex](https://quickstarts.snowflake.com/)

### Comunidad
- [Snowflake Community](https://community.snowflake.com/)
- [Stack Overflow - Snowflake](https://stackoverflow.com/questions/tagged/snowflake)

## Pr√≥ximos Pasos

Una vez que domines este ejemplo b√°sico, considera:

1. **Agregar m√°s fuentes de datos**: PDFs complejos, tablas de Snowflake, APIs externas
2. **Implementar reranking**: Mejorar la calidad de los resultados con scoring adicional
3. **Agregar memoria de conversaci√≥n**: Hacer que el chatbot recuerde el contexto
4. **Integrar con herramientas externas**: Email, Slack, MS Teams
5. **Implementar evaluaciones**: Medir la calidad de las respuestas RAG
6. **Optimizar prompts**: Experimentar con diferentes estrategias de prompting
7. **Agregar guardrails**: Validar inputs/outputs, detectar contenido inapropiado

## Contribuciones

Este proyecto es parte del repositorio de Hands-On Labs de Snowflake. Si encuentras errores o tienes sugerencias:

1. Abre un issue en el repositorio
2. Prop√≥n cambios con un pull request
3. Contacta al mantenedor del repo

## Licencia

Este proyecto est√° basado en el quickstart original de Snowflake, adaptado al espa√±ol.

---

## Cr√©ditos

**Adaptado por**: Juan Pablo Arrado  
**Basado en**: [Snowflake Cortex Search RAG Quickstart](https://github.com/Snowflake-Labs/sfguide-ask-questions-to-your-documents-using-rag-with-snowflake-cortex-search)  
**Fecha**: Noviembre 2025  

---

**¬øPreguntas? ¬øComentarios?**

Abre un issue en el repositorio o contacta al equipo de Snowflake.

¬°Feliz construcci√≥n de aplicaciones RAG! üöÄ

