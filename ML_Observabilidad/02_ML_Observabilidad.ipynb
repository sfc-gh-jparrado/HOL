{
 "metadata": {
  "kernelspec": {
   "display_name": "sp39",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  },
  "lastEditStatus": {
   "notebookId": "hhddciwqssntpdryemcm",
   "authorId": "1126630220347",
   "authorName": "JPARRADO",
   "authorEmail": "jorge.parrado@snowflake.com",
   "sessionId": "f47762da-10e9-476a-9d16-8781b19992a4",
   "lastEditTime": 1746585580553
  }
 },
 "nbformat_minor": 5,
 "nbformat": 4,
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3a5d316b-af86-4f60-93f4-8ed386bf5ce5",
   "metadata": {
    "name": "cell2",
    "collapsed": false
   },
   "source": "# Primeros pasos con la Observabilidad de ML en Snowflake\n\n## Resumen\n\nMLOps es una función central de la ingeniería de ML y se enfoca en agilizar el proceso de llevar modelos de machine learning a producción, y luego mantenerlos y monitorearlos de manera efectiva. A diferencia del software tradicional, los modelos de machine learning pueden cambiar su comportamiento con el tiempo debido a varios factores, incluyendo la deriva de entrada (input drift), suposiciones obsoletas del entrenamiento del modelo, problemas en los pipelines de datos (data pipelines), y desafíos estándar como los entornos de hardware/software y el tráfico. Estos factores pueden llevar a una disminución en el rendimiento del modelo y a un comportamiento inesperado que necesita ser monitoreado muy de cerca.\n\nSnowflake ML proporciona a las organizaciones un conjunto integrado de capacidades para machine learning de extremo a extremo en una única plataforma sobre datos gobernados. El comportamiento del modelo puede cambiar con el tiempo debido a la deriva de entrada (input drift), suposiciones de entrenamiento obsoletas, y problemas en los pipelines de datos (data pipelines), así como los factores habituales, incluyendo cambios en el hardware y software subyacentes y la naturaleza fluida del tráfico. La característica de Observabilidad de ML de Snowflake te permite rastrear la calidad de los modelos en producción que has desplegado a través del Snowflake Model Registry a través de múltiples dimensiones, como rendimiento, deriva y volumen.\n\nEste repositorio contiene un notebook que te guía a través de la construcción, despliegue y monitoreo de un modelo de predicción de abandono de clientes (customer churn prediction) en Snowflake.\n\n[Fuente](https://quickstarts.snowflake.com/guide/getting-started-with-ml-observability-in-snowflake/index.html#0)\n"
  },
  {
   "cell_type": "markdown",
   "id": "5b4d192a-ebd2-41f7-a992-55e5e40c68bc",
   "metadata": {
    "collapsed": false,
    "name": "Title",
    "resultHeight": 943
   },
   "source": "![](https://www.snowflake.com/wp-content/themes/snowflake/assets/img/brand-guidelines/logo-sno-blue-example.svg)\n\n# Construye, Despliega y Monitoriza tu Modelo en Snowflake\n\nEn esta laboratorio veremos cómo es un ciclo de vida completo de un modelo en Snowflake.\nUtilizaremos las siguientes funcionalidades de Snowflake:\n\n* Snowflake ML Python SDK\n* Registro de Modelos\n* Observabilidad de ML\n* Alertas\n* Monitorización de Deriva\n\n![](https://drive.google.com/file/d/1jWryVEAjyetHMRgTTMo_bnx_BZRdeNuC/view?usp=sharing)\n\n>**Caso de uso:** Su empresa está teniendo problamas con la pérdida de clientes a manos de la competencia. Deseas comprender la probabilidad de que cada uno de los clientes abandone, con el objetivo, de tomar las medidas necesarias para los usuarios con alta probabilidad de abandono. Con el tiempo, se observa una nueva tendencia en la pérdida de clientes que debe abordarse de inmediato para obtener una ventaja competitiva. La institución financiera aprovecha el panel de Observabilidad de ML para ver las métricas y los factores de precisión. Puede tomar medidas proactivas para reentrenar el modelo y también comparar diferentes versiones del modelo monitorizando el rendimiento del modelo.\n\n### **Características**\n\n* **CREDITSCORE:** Puntuación de crédito del cliente basada en su comportamiento y gestión crediticia histórica\n* **GEOGRAPHY:** País de residencia\n* **GENDER:** Género del cliente\n* **AGE:** Edad del cliente\n* **TENURE:** Duración en años que han sido cliente\n* **BALANCE:** Saldo actual de su cuenta bancaria\n* **NUMOFPRODUCTS:** Número de productos comprados al banco\n* **HASCRCARD:** ¿Tiene el cliente tarjeta de crédito? - 1 si la tiene, 0 si no\n* **ISACTIVEMEMBER:** ¿Ha utilizado el cliente su cuenta bancaria en los últimos 3 meses? - 1 si lo hizo, 0 si no lo hizo\n* **ESTIMATEDSALARY:** Salario estimado del cliente\n* **DEBTTOINCOME:** Relación deuda-ingresos\n\n### **Modelo**\n\nConstruiremos un modelo de clasificación utilizando el framework XGBoost con la API de ML de Snowflake y registraremos el modelo en el registro. A lo largo del proceso, crearemos monitores de modelo y veremos el rendimiento del modelo en el panel de Snowsight."
  },
  {
   "cell_type": "markdown",
   "id": "6d6cd626-098f-4e67-82f4-83a9b11dc50b",
   "metadata": {
    "name": "cell1",
    "collapsed": false
   },
   "source": "#### Agrega los siguientes paquetes: `snowflake-ml-python`,`snowflake-snowpark-python`"
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "3775908f-ca36-4846-8f38-5adca39217f2",
   "metadata": {
    "codeCollapsed": false,
    "collapsed": false,
    "language": "python",
    "name": "importheaders",
    "resultHeight": 54
   },
   "outputs": [],
   "source": "# Import python packages\nimport streamlit as st\nimport pandas as pd\n\nfrom snowflake.snowpark.context import get_active_session\nsession = get_active_session()\nfrom datetime import datetime, timedelta\nfrom snowflake.ml.registry import Registry\nimport joblib\nfrom snowflake.ml.modeling.pipeline import Pipeline\nimport snowflake.ml.modeling.preprocessing as pp\nfrom snowflake.ml.modeling.xgboost import XGBClassifier\nfrom snowflake.snowpark.types import StringType, IntegerType\nimport snowflake.snowpark.functions as F\nfrom snowflake.snowpark.functions import col, current_date, dateadd, random, floor,current_date, datediff\nimport warnings\nwarnings.filterwarnings('ignore')\n\nsession.query_tag = {\"origin\":\"sf_sit-is\", \"name\":\"mlops_customerchurn\", \"version\":{\"major\":1, \"minor\":0}}\n\nimport snowflake.snowpark.functions as F\nfrom IPython.display import Markdown, display\n\nsolution_prefix = session.get_current_warehouse()\nsolution_prefix"
  },
  {
   "cell_type": "markdown",
   "id": "3e51a542-d06f-42fc-ad28-2f408f940b04",
   "metadata": {
    "collapsed": false,
    "name": "load_data",
    "resultHeight": 46
   },
   "source": "### Cargar datos sintéticos del data_stage a una tabla de Snowflake usando un comando COPY INTO."
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "a8a2ccd3-075f-4a1e-9ab0-00e248cc9e4e",
   "metadata": {
    "codeCollapsed": false,
    "collapsed": false,
    "language": "sql",
    "name": "initial_customer_dataset",
    "resultHeight": 111
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total exited customers: 1714 (Target: ~2000)\n",
      "   CustomerId  Surname  CreditScore Geography  Gender  Age  Tenure    Balance  \\\n",
      "0           1    Johns          402    France    Male   55       9   91944.03   \n",
      "1           2  Schultz          735     Spain    Male   59       8  126536.56   \n",
      "2           3    Jones          570     Spain    Male   54       7  191357.66   \n",
      "3           4    Baker          406    France  Female   73       3  125263.00   \n",
      "4           5  Aguirre          371     Spain    Male   88       9  195626.75   \n",
      "\n",
      "   NumOfProducts  HasCrCard  IsActiveMember  EstimatedSalary  Exited  \\\n",
      "0              1          1               1         36899.18       0   \n",
      "1              2          0               0         33120.74       0   \n",
      "2              2          1               1         34751.09       1   \n",
      "3              4          0               0        169844.77       0   \n",
      "4              4          0               1         13787.72       0   \n",
      "\n",
      "  TransactionTimestamp  debttoincome  \n",
      "0  2022-01-09 14:08:54            23  \n",
      "1  2022-04-19 06:29:13            80  \n",
      "2  2022-07-11 11:43:59            29  \n",
      "3  2022-12-03 05:38:57            24  \n",
      "4  2022-10-30 09:17:13            80  \n"
     ]
    }
   ],
   "source": [
    "-- Create csv format\n",
    "CREATE FILE FORMAT IF NOT EXISTS CSVFORMAT \n",
    "    SKIP_HEADER = 1 \n",
    "    TYPE = 'CSV';\n",
    "    \n",
    "CREATE OR REPLACE STAGE data_stage\n",
    "    FILE_FORMAT = (TYPE = 'CSV') \n",
    "    URL = 's3://sfquickstarts/sfguide_getting_started_with_ml_observability_in_snowflake/mlops_customerchurn.csv';\n",
    "    \n",
    "-- Inspect content of stage\n",
    "LS @data_stage;\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5283d28-3f4b-4247-93c3-43dc4e305315",
   "metadata": {
    "collapsed": false,
    "name": "read_csv_file",
    "resultHeight": 46
   },
   "source": "### Leer un archivo CSV usando Snowpark desde un stage en Snowflake a un DataFrame."
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "a349023c-8855-4b60-8bdd-35ec51c48141",
   "metadata": {
    "codeCollapsed": false,
    "collapsed": false,
    "language": "python",
    "name": "CUSTOMERS_DATA",
    "resultHeight": 0
   },
   "outputs": [],
   "source": [
    "spdf = session.read.options({\"field_delimiter\": \",\",\n",
    "                                    \"field_optionally_enclosed_by\": '\"',\n",
    "                                    \"infer_schema\": True,\n",
    "                                    \"parse_header\": True}).csv(\"@data_stage\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "id": "cb77670b-0bfb-4824-8b80-b12a0948b8a4",
   "metadata": {
    "language": "python",
    "name": "cast",
    "collapsed": false
   },
   "outputs": [],
   "source": "from snowflake.snowpark.types import DecimalType, FloatType, DoubleType\n\n# Get schema of the DataFrame\nschema = spdf.schema.fields\n\n# Identify columns that are of type NUMBER (DecimalType)\nnum_columns = [col.name for col in schema if isinstance(col.datatype, DecimalType)]\n\n# Convert columns to FLOAT\nfor col in num_columns:\n    spdf = spdf.with_column(col, spdf[col].cast(DoubleType()))\n\n",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "7ca65646-6250-41ec-bdae-277bc86e7b44",
   "metadata": {
    "language": "python",
    "name": "date_advance",
    "collapsed": false
   },
   "outputs": [],
   "source": "from snowflake.snowpark import Session\nfrom snowflake.snowpark.functions import col, current_date, dateadd, to_date,lit\n\n# Step 1: Get today's date\ntodays_date = datetime.now()\n\nlatest_date = max(spdf.select('TRANSACTIONTIMESTAMP').collect())[0]\n\n# Step 3: Calculate the difference in days\ndiff_days = (todays_date - latest_date).days - 1\n\ndf = spdf.with_column(\n    \"TRANSACTIONTIMESTAMP\", \n    dateadd(\"day\", lit(diff_days), col(\"TRANSACTIONTIMESTAMP\"))\n)\n\n\ndf = df.with_column(\n    \"CREDITSCORE\", col(\"CREDITSCORE\").cast(\"float\")\n)\ndf = df.with_column(\n    \"PREDICTED_CHURN\", F.lit(9999)\n)\ndf.show()\n\ndf.write.mode(\"overwrite\").save_as_table(\"CUSTOMERS\")\n",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "b4b2b17b-ba3b-4eb0-b302-585f066f87ab",
   "metadata": {
    "codeCollapsed": false,
    "collapsed": false,
    "language": "python",
    "name": "remove_rownum",
    "resultHeight": 350
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "|\"CUSTOMERID\"  |\"CREDITSCORE\"  |\"GEOGRAPHY\"  |\"GENDER\"  |\"AGE\"  |\"TENURE\"  |\"BALANCE\"  |\"NUMOFPRODUCTS\"  |\"HASCRCARD\"  |\"ISACTIVEMEMBER\"  |\"ESTIMATEDSALARY\"  |\"EXITED\"  |\"TRANSACTIONTIMESTAMP\"  |\"DEBTTOINCOME\"  |\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "|1             |402            |France       |Male      |55     |9         |91944.03   |1                |1            |1                 |36899.18           |0         |2022-01-09 14:08:54     |23              |\n",
      "|2             |735            |Spain        |Male      |59     |8         |126536.56  |2                |0            |0                 |33120.74           |0         |2022-04-19 06:29:13     |80              |\n",
      "|3             |570            |Spain        |Male      |54     |7         |191357.66  |2                |1            |1                 |34751.09           |1         |2022-07-11 11:43:59     |29              |\n",
      "|4             |406            |France       |Female    |73     |3         |125263.0   |4                |0            |0                 |169844.77          |0         |2022-12-03 05:38:57     |24              |\n",
      "|5             |371            |Spain        |Male      |88     |9         |195626.75  |4                |0            |1                 |13787.72           |0         |2022-10-30 09:17:13     |80              |\n",
      "|6             |320            |Germany      |Male      |72     |7         |28858.19   |3                |1            |0                 |48456.88           |0         |2023-11-26 06:10:34     |95              |\n",
      "|7             |421            |Spain        |Male      |71     |6         |15990.69   |3                |1            |0                 |191619.44          |1         |2022-10-02 08:53:11     |49              |\n",
      "|8             |766            |Spain        |Male      |39     |4         |39715.24   |1                |0            |1                 |22544.05           |0         |2022-01-17 10:34:53     |76              |\n",
      "|9             |514            |Spain        |Male      |44     |6         |193003.03  |3                |1            |1                 |16901.08           |0         |2022-01-15 01:31:26     |52              |\n",
      "|10            |630            |France       |Female    |64     |6         |189832.56  |3                |1            |1                 |83592.57           |0         |2023-12-09 06:53:42     |56              |\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spdf= df.drop('ROWNUMBER')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af5f72cd-5892-4656-ae23-3db6ffb1cd8e",
   "metadata": {
    "collapsed": false,
    "name": "preprocessing",
    "resultHeight": 66
   },
   "source": "#### Define un pipeline de preprocesamiento usando Pipeline con dos pasos: Ordinal Encoding (Codificación Ordinal) para columnas categóricas y Escalado Min-Max para columnas numéricas. Luego divide los datos en conjuntos de entrenamiento y prueba, aplica los pasos de preprocesamiento a los datos de entrenamiento y guarda el pipeline como un archivo joblib (preprocessing_pipeline.joblib)."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a92413c3-0dea-4d98-a70a-0c77c72b0397",
   "metadata": {
    "codeCollapsed": false,
    "collapsed": false,
    "language": "python",
    "name": "preprocessing_pipeline_",
    "resultHeight": 287
   },
   "outputs": [],
   "source": "num_cols = ['ESTIMATEDSALARY', 'BALANCE', 'CREDITSCORE','AGE','TENURE','DEBTTOINCOME']\noutput_cols=['EstimatedSalary_SS', 'Balance_SS', 'CreditScore_SS','Age_SS','Tenure_SS','debttoincome_SS']\n\ncat_cols = ['HasCrCard', 'IsActiveMember', 'Geography','Gender', 'NumOfProducts']\nstring_columns = ['GEOGRAPHY', 'GENDER']\nstring_columns_oe = ['GEOGRAPHY_oe', 'GENDER_oe']\npreprocessing_pipeline = Pipeline(\n    steps=[\n            (\n                \"OE\",\n                pp.OrdinalEncoder(\n                    input_cols=string_columns,\n                    output_cols=string_columns_oe,\n                    drop_input_cols= False,\n                )\n                \n            ),\n            (\n                \"MMS\",\n                pp.MinMaxScaler(\n                    clip=True,\n                    input_cols=num_cols,\n                    output_cols=output_cols,\n                    drop_input_cols= False,\n                )\n            )\n    ]\n)\n\nPIPELINE_FILE = '/tmp/preprocessing_pipeline.joblib'\njoblib.dump(preprocessing_pipeline, PIPELINE_FILE) # We are just pickling it locally first\ntraining, testing = spdf.random_split(weights=[0.8, 0.2], seed=111)\ntraining_spdf = preprocessing_pipeline.fit(training).transform(training)\ntesting_spdf=preprocessing_pipeline.fit(testing).transform(testing)"
  },
  {
   "cell_type": "markdown",
   "id": "b5deeba5-4197-4a01-b93a-c797cbe13925",
   "metadata": {
    "collapsed": false,
    "name": "save_pipeline",
    "resultHeight": 47
   },
   "source": "#### Almacenar el archivo del pipeline en un stage"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "209b6772-3e92-49c1-a969-6f8a03ba7c8a",
   "metadata": {
    "codeCollapsed": false,
    "collapsed": false,
    "language": "python",
    "name": "ml_stage",
    "resultHeight": 354
   },
   "outputs": [],
   "source": [
    "session.sql(\"CREATE or replace stage ML_STAGE\").collect()\n",
    "session.file.put(PIPELINE_FILE, \"@ML_STAGE\", overwrite=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff15b984-9294-4e35-a76e-1e6210653ed9",
   "metadata": {
    "codeCollapsed": false,
    "collapsed": false,
    "language": "sql",
    "name": "view_stage",
    "resultHeight": 111
   },
   "outputs": [],
   "source": [
    "ls @ML_STAGE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a3bc115-40c0-4012-a5f5-c0a92b28e0fa",
   "metadata": {
    "collapsed": false,
    "name": "build_model",
    "resultHeight": 60
   },
   "source": "## Construir el modelo XGBClassifier y entrenarlo usando los datos de entrenamiento"
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "7af4a413-9d63-497e-a7a3-237553a363e1",
   "metadata": {
    "codeCollapsed": false,
    "collapsed": false,
    "language": "python",
    "name": "DEMO____initial_training",
    "resultHeight": 671
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<snowflake.snowpark.dataframe.DataFrame at 0x33cc21a60>"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": "num_cols = ['EstimatedSalary', 'Balance', 'CreditScore','Age','Tenure','debttoincome']\n\ncat_cols = ['HasCrCard', 'IsActiveMember', 'GEOGRAPHY','GENDER', 'NumOfProducts']\nTarget = [\"EXITED\"]\n\nfeature_names_input = [c for c in training_spdf.columns if c not in [\"EXITED\", \"TRANSACTIONTIMESTAMP\", \"CUSTOMERID\",\"ESTIMATEDSALARY\", \"BALANCE\", \"CREDITSCORE\",\"AGE\",\"TENURE\",\"DEBTTOINCOME\",\"GEOGRAPHY\",\"GENDER\",\"PREDICTED_CHURN\"]]\n\n\ntraining_spdf = training_spdf.with_column(\n    \"CREDITSCORE_SS\", col(\"CREDITSCORE_SS\").cast(\"float\")\n)\noutput_label = [\"PREDICTED_CHURN\"]\n# Initialize a XGBClassifier object with input, label, and output column names\nmodel = XGBClassifier(\n    input_cols=feature_names_input,\n    label_cols=Target,\n    output_cols=output_label\n    \n)\n\n# Train the classifier model using the training set\n_ = model.fit(training_spdf)\n\n"
  },
  {
   "cell_type": "markdown",
   "id": "cc86a6fb-7dba-4ba0-91b7-a0428301b3f2",
   "metadata": {
    "collapsed": false,
    "name": "init_registry",
    "resultHeight": 46
   },
   "source": "### Inicializar el Snowflake Model Registry\n\nRegistrar y gestionar el modelo de aprendizaje automático entrenado en Snowflake.\n\nObserva que task=type_hints.Task.TABULAR_BINARY_CLASSIFICATION: Especifica que esta es una tarea de clasificación binaria (predecir el churn: Yes/No)."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "063b1cba-2e57-4508-9601-9955ac7a830e",
   "metadata": {
    "codeCollapsed": false,
    "collapsed": false,
    "language": "python",
    "name": "DEMO____log_model",
    "resultHeight": 111
   },
   "outputs": [],
   "source": "from snowflake.ml.registry import Registry\nfrom snowflake.ml.model import type_hints\n\nreg = Registry(session=session)\n\nMODEL_NAME = \"QS_CustomerChurn_classifier\"\nMODEL_VERSION = \"v1\"\n\nmv = reg.log_model(model,\n                   model_name=MODEL_NAME,\n                   version_name=MODEL_VERSION,\n                   options={'relax_version': True},\n                   task=type_hints.Task.TABULAR_BINARY_CLASSIFICATION)\nreg.show_models()\n"
  },
  {
   "cell_type": "markdown",
   "id": "a93bde85-0531-4ec5-b0ac-6b3baf7502fd",
   "metadata": {
    "collapsed": false,
    "name": "inference_fn",
    "resultHeight": 60
   },
   "source": "## Inferencia Continua\nLa función de inferencia realiza predicciones utilizando un modelo preentranado de aprendizaje automático dentro de Snowflake. Esta función utiliza el pipeline de preprocesamiento creado anteriormente para asegurar que los datos se transformen de manera consistente.\n✅ Ejecuta predicciones utilizando una versión registrada del modelo.\n✅ Actualiza las predicciones directamente en la tabla de Snowflake.\n✅ Maneja eficientemente la inferencia en batch con actualizaciones SQL."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4709bd3d-7c4d-4bc3-aa99-ba3ea627ec31",
   "metadata": {
    "codeCollapsed": false,
    "collapsed": false,
    "language": "python",
    "name": "inference_utils",
    "resultHeight": 432
   },
   "outputs": [],
   "source": "from snowflake.ml.modeling.pipeline import Pipeline\nimport snowflake.ml.modeling.preprocessing as pp\nimport snowflake.snowpark.functions as F\n\ndef inference(table_name, modelname, modelversion) -> str:\n    reg = Registry(session=session)\n    m = reg.get_model(modelname)\n    mv = m.version(modelversion)\n    \n    # Load preprocessing pipeline from a file\n    session.file.get('@ML_STAGE/preprocessing_pipeline.joblib.gz', '/tmp')\n    pipeline_file = '/tmp/preprocessing_pipeline.joblib.gz'\n    \n    \n    preprocessing_pipeline = joblib.load(pipeline_file)\n    \n    df = session.table(table_name)\n    \n    # Apply preprocessing\n    testing_spdf = preprocessing_pipeline.fit(df).transform(df)\n    testing_spdf = testing_spdf.with_column(\n    \"CREDITSCORE_SS\", col(\"CREDITSCORE_SS\").cast(\"float\")\n)\n    # Perform prediction\n    results = mv.run(testing_spdf, function_name=\"predict\")\n    results =results.drop(\"CREDITSCORE_SS\", \"BALANCE_SS\", \"DEBTTOINCOME_SS\", \"TENURE_SS\", \"AGE_SS\", \"ESTIMATEDSALARY_SS\", \"GENDER_OE\", \"GEOGRAPHY_OE\")\n    #results.write.save_as_table(\"customer_churn\", mode=\"overwrite\")\n    results.create_or_replace_temp_view(\"results_temp\")\n    update_statement = f\"\"\"\n    UPDATE {table_name} t\n    SET PREDICTED_CHURN = r.PREDICTED_CHURN\n    FROM results_temp r\n    WHERE t.CUSTOMERID = r.CUSTOMERID\n    AND t.TRANSACTIONTIMESTAMP=r.TRANSACTIONTIMESTAMP;\n\"\"\"\n\n    # Execute the merge statement\n    session.sql(update_statement).collect()\n        \n    return \"Success\"\n"
  },
  {
   "cell_type": "markdown",
   "id": "12894ad5-c3a5-411d-bea7-7037fc9521d1",
   "metadata": {
    "name": "mkpredict1",
    "collapsed": false
   },
   "source": "Ejecuta el modelo entrenado sobre el DataFrame testing_spdf usando mv.run(). function_name=\"predict\" especifica que la función a utilizar para la inferencia es \"predict\". La salida es un DataFrame que contiene las predicciones."
  },
  {
   "cell_type": "code",
   "id": "c3a4955a-9eda-4eb9-99eb-9156b526998a",
   "metadata": {
    "language": "python",
    "name": "inference_results",
    "collapsed": false
   },
   "outputs": [],
   "source": "testing_spdf = testing_spdf.with_column(\n    \"CREDITSCORE_SS\", col(\"CREDITSCORE_SS\").cast(\"float\")\n)\n# Perform prediction\nresults = mv.run(testing_spdf, function_name=\"predict\")\nresults",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "ccb54964-9adb-416d-898f-4e61a169bca2",
   "metadata": {
    "name": "SIMULATION",
    "collapsed": false
   },
   "source": "## DATA DRIFT (DERIVA DE DATOS) Y OBSERVABILIDAD EN EL PANEL DE OBSERVABILIDAD DE ML\n"
  },
  {
   "cell_type": "markdown",
   "id": "cdcea649-de3b-4859-81fb-338d5d9fc007",
   "metadata": {
    "name": "mkdrift",
    "collapsed": false
   },
   "source": "Ahora veamos cómo se puede monitorizar una deriva de datos y cómo una acción proactiva podría ayudar a la firma financiera a prevenir el abandono de clientes."
  },
  {
   "cell_type": "code",
   "id": "813f4936-3811-4ecf-b737-e33fbca0afa0",
   "metadata": {
    "language": "sql",
    "name": "read_drift_data",
    "collapsed": false
   },
   "outputs": [],
   "source": "-- Create csv format\nCREATE FILE FORMAT IF NOT EXISTS CSVFORMAT \n    SKIP_HEADER = 1 \n    TYPE = 'CSV';\n    \nCREATE OR REPLACE STAGE data_stage\n    FILE_FORMAT = (TYPE = 'CSV') \n    URL = 's3://sfquickstarts/sfguide_getting_started_with_ml_observability_in_snowflake/CUSTOMERS_DRIFTED.csv';\n    \n-- Inspect content of stage\nLS @data_stage;\n\n\n",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "1841cf81-4e9c-4929-bc9e-89a9af3c9d3a",
   "metadata": {
    "name": "mkcustdrift",
    "collapsed": false
   },
   "source": "Los datos en el archivo CUSTOMERS_DRIFTED contienen nuevas tendencias de clientes que llevan a una baja precisión de la inferencia usando la versión v1 del modelo."
  },
  {
   "cell_type": "code",
   "id": "71246d5a-ad5f-4804-98c9-d423047f9bd0",
   "metadata": {
    "language": "python",
    "name": "datatype_Cast",
    "collapsed": false
   },
   "outputs": [],
   "source": "spdf = session.read.options({\"field_delimiter\": \",\",\n                                    \"field_optionally_enclosed_by\": '\"',\n                                    \"infer_schema\": True,\n                                    \"parse_header\": True}).csv(\"@data_stage\")\n\nfrom snowflake.snowpark.types import DecimalType, FloatType\n\n# Get schema of the DataFrame\nschema = spdf.schema.fields\n\n# Identify columns that are of type NUMBER (DecimalType)\nnum_columns = [col.name for col in schema if isinstance(col.datatype, DecimalType)]\n\n# Convert columns to FLOAT\nfor col in num_columns:\n    spdf = spdf.with_column(col, spdf[col].cast(FloatType()))\n\n\nfrom snowflake.snowpark.functions import col, current_date, dateadd, to_date, lit,to_timestamp\nfrom datetime import datetime\n\n# Step 1: Get today's date\ntodays_date = datetime.now()\n\n# Ensure TRANSACTIONTIMESTAMP is stored as a string first\nspdf = spdf.with_column(\"TRANSACTIONTIMESTAMP\", col(\"TRANSACTIONTIMESTAMP\").cast(\"string\"))\n\n# Get the latest date from the dataset\nlatest_date_str = max(spdf.select('TRANSACTIONTIMESTAMP').collect())[0]\n\n# Convert latest_date to datetime\nlatest_date = datetime.strptime(latest_date_str, '%m/%d/%y %H:%M')\n\n# Step 3: Calculate the difference in days\ndiff_days = (todays_date - latest_date).days - 1\n\n# Apply date adjustment\ndf = spdf.with_column(\n    \"TRANSACTIONTIMESTAMP\",\n    dateadd(\"day\", lit(diff_days), to_timestamp(col(\"TRANSACTIONTIMESTAMP\"), 'MM/DD/YY HH24:MI'))\n)\n\n# Cast CREDIT SCORE to float\ndf = df.with_column(\"CREDITSCORE\", col(\"CREDITSCORE\").cast(\"float\"))\n\n# Add PREDICTED_CHURN column\nspdf_drift = df.with_column(\"PREDICTED_CHURN\", lit(9999))\n\nspdf_drift.show()\n",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "e292f2b9-e023-4d96-bef2-f183ebf97fe6",
   "metadata": {
    "name": "mk1",
    "collapsed": false
   },
   "source": "La firma financiera realiza las predicciones con la deriva de datos usando la versión v1 del modelo. Los datos derivados se guardan en la tabla CUSTOMERS_DRIFTED. Una copia de los mismos datos se guarda en la tabla CUSTOMERS_EVAL para mostrar cómo se monitorizó esa deriva y se reentrenó un nuevo modelo de forma proactiva para evitar la toma de decisiones inexactas."
  },
  {
   "cell_type": "code",
   "id": "91d791e8-e863-4842-b7f8-835a12072837",
   "metadata": {
    "language": "python",
    "name": "CUSTOMERS_DRIFTED_table",
    "collapsed": false
   },
   "outputs": [],
   "source": "\ncurrent_columns = spdf_drift.columns \nnew_columns = [col.strip('\"') for col in current_columns] \n\nspdf_drift = spdf_drift.select([spdf_drift[col].alias(new_col) for col, new_col in zip(current_columns, new_columns)])\nspdf_drift = spdf_drift.with_column(\n    \"CREDITSCORE\", col(\"CREDITSCORE\").cast(\"float\")\n)\nspdf_drift.write.mode(\"overwrite\").save_as_table(\"CUSTOMERS_DRIFTED\")\nspdf_drift.write.mode(\"overwrite\").save_as_table(\"CUSTOMERS_EVAL\")\n",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "a5ce8079-4ddd-41df-a8cb-b867deb7098b",
   "metadata": {
    "collapsed": false,
    "name": "DEMO____Monitoring",
    "resultHeight": 115
   },
   "source": "# Habilitar la Monitorización\nCrea un monitor para sus modelos utilizando el comando CREATE MODEL MONITOR. El objeto monitor refresca automáticamente los registros del monitor consultando los datos de origen y actualiza los informes de monitorización basándose en los registros. El primero que está comentado muestra el método Pythonic y la siguiente celda muestra cómo monitorizar usando SQL."
  },
  {
   "cell_type": "code",
   "id": "9a75f3e5-e8b1-495a-bb89-522f2f8dc191",
   "metadata": {
    "language": "python",
    "name": "pythonic_modelmonitor",
    "collapsed": true,
    "codeCollapsed": false
   },
   "outputs": [],
   "source": "'''\nreg = Registry(session=session,options={\"enable_monitoring\": True})\nmodelname='QS_CustomerChurn_classifier'\nmodelversion='v1'\nm = reg.get_model(modelname)\nmv = m.version(modelversion)\n\n# Fetch model version that will be monitored\nmodel_version = mv\n\nfrom snowflake.ml.monitoring.entities.model_monitor_config import ModelMonitorConfig, ModelMonitorSourceConfig\nsource_config = ModelMonitorSourceConfig(\n    source=\"CUSTOMERS_DRIFTED\",\n    baseline=\"CUSTOMERS\",\n    timestamp_column=\"TRANSACTIONTIMESTAMP\",\n    prediction_class_columns=[\"PREDICTED_CHURN\"],\n    actual_class_columns=[\"EXITED\"],\n    id_columns=[\"CUSTOMERID\"],\n)\n\n# Set up config for ModelMonitor.\nmodel_monitor_config = ModelMonitorConfig(\n    model_version=model_version,\n    model_function_name=\"predict\",\n    background_compute_warehouse_name=\"ml_wh\",\n)\n\n# Add a new ModelMonitor\nmodel_monitor = reg.add_monitor(\n    name=f\"CHURN_MODEL_MONITOR\", \n    source_config=source_config,\n    model_monitor_config=model_monitor_config,\n)\nmodel_monitor\n'''",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "4feedabf-0d1b-4efa-af01-9b3a38df68ea",
   "metadata": {
    "name": "sqlmm",
    "collapsed": false
   },
   "source": "## Versión SQL para crear el monitor del modelo"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2047644f-ab0a-4447-b573-2afd3c20f739",
   "metadata": {
    "language": "python",
    "name": "DEMO____ADD_MONITOR",
    "resultHeight": 111,
    "collapsed": false
   },
   "outputs": [],
   "source": "query = f\"\"\"\nCREATE OR REPLACE MODEL MONITOR CHURN_MODEL_MONITOR\nWITH\n    MODEL=QS_CustomerChurn_classifier\n    VERSION=v1\n    FUNCTION=predict\n    SOURCE=CUSTOMERS_DRIFTED\n    BASELINE=CUSTOMERS\n    TIMESTAMP_COLUMN=TRANSACTIONTIMESTAMP\n    PREDICTION_CLASS_COLUMNS=(PREDICTED_CHURN)  \n    ACTUAL_CLASS_COLUMNS=(EXITED)\n    ID_COLUMNS=(CUSTOMERID)\n    WAREHOUSE=ML_WH\n    REFRESH_INTERVAL='1 min'\n    AGGREGATION_WINDOW='1 day';\n\"\"\"\nsession.sql(query).collect()"
  },
  {
   "cell_type": "markdown",
   "id": "8bb50723-976e-4be4-934a-2845f4208a6b",
   "metadata": {
    "name": "predict2",
    "collapsed": false
   },
   "source": "\n## Predecir el churn (abandono) para las nuevas tendencias de clientes"
  },
  {
   "cell_type": "code",
   "id": "1df4e58d-10a2-4754-a750-6018310caf4f",
   "metadata": {
    "language": "python",
    "name": "inference_1",
    "collapsed": false
   },
   "outputs": [],
   "source": "status= inference('CUSTOMERS_DRIFTED','QS_CUSTOMERCHURN_CLASSIFIER', 'v1');",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "9c9e6b74-699e-4b7a-b281-0aa6ca925b79",
   "metadata": {
    "collapsed": false,
    "name": "DEMO____Dashboard",
    "resultHeight": 83
   },
   "source": "Veamos cómo se ven las predicciones de abandono y las métricas. \n\nAbre el Panel navegando a Studio->Models.\n\nHaz clic en tu modelo y elige el monitor que acabas de añadir arriba. Cambia el rango de fechas a \"Últimos 3 meses\"."
  },
  {
   "cell_type": "code",
   "id": "dc285676-763b-4bf8-91e9-b123f2774e84",
   "metadata": {
    "language": "sql",
    "name": "RETRAINING_DATA",
    "collapsed": false
   },
   "outputs": [],
   "source": "-- Create csv format\nCREATE FILE FORMAT IF NOT EXISTS CSVFORMAT \n    SKIP_HEADER = 1 \n    TYPE = 'CSV';\n    \nCREATE OR REPLACE STAGE data_stage\n    FILE_FORMAT = (TYPE = 'CSV') \n    URL = 's3://sfquickstarts/sfguide_getting_started_with_ml_observability_in_snowflake/CUSTOMERS_TRAINING.csv';\n    \n-- Inspect content of stage\nLS @data_stage;\n",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "0d39a9f9-be64-491d-8df3-595c3bbf51d6",
   "metadata": {
    "name": "mkretrain",
    "collapsed": false
   },
   "source": "## Se puede encontrar que la deriva de datos y la deriva de concepto han impactado significativamente el rendimiento del modelo con el tiempo.\n\nPara mantener la precisión, los modelos requieren reentrenamiento periódicamente. A continuación se muestra cómo se maneja esto en el pipeline de predicción de abandono de clientes. Ahora reentrenemos los datos con las nuevas tendencias."
  },
  {
   "cell_type": "code",
   "id": "1e71c4a1-fd06-42c5-8af7-1483ce44fae3",
   "metadata": {
    "language": "python",
    "name": "preprocess_retraining_data",
    "collapsed": false
   },
   "outputs": [],
   "source": "spdf = session.read.options({\"field_delimiter\": \",\",\n                                    \"field_optionally_enclosed_by\": '\"',\n                                    \"infer_schema\": True,\n                                    \"parse_header\": True}).csv(\"@data_stage\")\n\nfrom snowflake.snowpark.types import DecimalType, FloatType\n\n# Get schema of the DataFrame\nschema = spdf.schema.fields\n\n# Identify columns that are of type NUMBER (DecimalType)\nnum_columns = [col.name for col in schema if isinstance(col.datatype, DecimalType)]\n\n# Convert columns to FLOAT\nfor col in num_columns:\n    spdf = spdf.with_column(col, spdf[col].cast(FloatType()))\n\n\nfrom snowflake.snowpark.functions import col, current_date, dateadd, to_date, lit,to_timestamp\nfrom datetime import datetime\n\n# Step 1: Get today's date\ntodays_date = datetime.now()\n\n# Ensure TRANSACTIONTIMESTAMP is stored as a string first\nspdf = spdf.with_column(\"TRANSACTIONTIMESTAMP\", col(\"TRANSACTIONTIMESTAMP\").cast(\"string\"))\n\n# Get the latest date from the dataset\nlatest_date_str = max(spdf.select('TRANSACTIONTIMESTAMP').collect())[0]\n\n# Convert latest_date to datetime\nlatest_date = datetime.strptime(latest_date_str, '%m/%d/%y %H:%M')\n\n# Step 3: Calculate the difference in days\ndiff_days = (todays_date - latest_date).days - 1\n\n# Apply date adjustment\ndf = spdf.with_column(\n    \"TRANSACTIONTIMESTAMP\",\n    dateadd(\"day\", lit(diff_days), to_timestamp(col(\"TRANSACTIONTIMESTAMP\"), 'MM/DD/YY HH24:MI'))\n)\n\n# Cast CREDIT SCORE to float\ndf = df.with_column(\"CREDITSCORE\", col(\"CREDITSCORE\").cast(\"float\"))\n\n# Add PREDICTED_CHURN column\nspdf_drift = df.with_column(\"PREDICTED_CHURN\", lit(9999))\n\nspdf_drift.show()\n\ncurrent_columns = spdf_drift.columns \nnew_columns = [col.strip('\"') for col in current_columns] \n\nspdf_drift = spdf_drift.select([spdf_drift[col].alias(new_col) for col, new_col in zip(current_columns, new_columns)])\nspdf_drift = spdf_drift.with_column(\n    \"CREDITSCORE\", col(\"CREDITSCORE\").cast(\"float\")\n)\n\n\nspdf_drift.write.mode(\"overwrite\").save_as_table(\"CUSTOMERS_TRAINING\")\n",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "9a756567-1ec8-454b-b58d-d7c037f8d01c",
   "metadata": {
    "language": "python",
    "name": "retrain_model",
    "collapsed": false
   },
   "outputs": [],
   "source": "# Load preprocessing pipeline from a file\nsession.file.get('@ML_STAGE/preprocessing_pipeline.joblib.gz', '/tmp')\npipeline_file = '/tmp/preprocessing_pipeline.joblib.gz'\n\n\npreprocessing_pipeline = joblib.load(pipeline_file)\n\n# Apply preprocessing\ntraining_spdf = preprocessing_pipeline.fit(spdf_drift).transform(spdf_drift)\ntraining_spdf = training_spdf.with_column(\n\"CREDITSCORE_SS\", col(\"CREDITSCORE_SS\").cast(\"float\")\n)\n\nnum_cols = ['EstimatedSalary', 'Balance', 'CreditScore','Age','Tenure','debttoincome']\n\ncat_cols = ['HasCrCard', 'IsActiveMember', 'GEOGRAPHY','GENDER', 'NumOfProducts']\nTarget = [\"EXITED\"]\n\nfeature_names_input = [c for c in training_spdf.columns if c not in [\"EXITED\", \"TRANSACTIONTIMESTAMP\", \"CUSTOMERID\",\"ESTIMATEDSALARY\", \"BALANCE\", \"CREDITSCORE\",\"AGE\",\"TENURE\",\"DEBTTOINCOME\",\"GEOGRAPHY\",\"GENDER\",\"PREDICTED_CHURN\",\"DATASET_TYPE\"]]\n\noutput_label = [\"PREDICTED_CHURN\"]\n# Initialize a XGBClassifier object with input, label, and output column names\nmodel = XGBClassifier(\n    input_cols=feature_names_input,\n    label_cols=Target,\n    output_cols=output_label\n    \n)\n\n# Train the classifier model using the training set\n_ = model.fit(training_spdf)\n",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "fb0bedb9-b8b6-4f3f-ba56-66e59ef5d678",
   "metadata": {
    "name": "mk",
    "collapsed": false
   },
   "source": "## Registrar el modelo como una nueva versión V2 con el mismo nombre de modelo QS_CustomerChurn_classifier"
  },
  {
   "cell_type": "code",
   "id": "9a004951-afdc-4461-8d5e-efc2d4d4fef1",
   "metadata": {
    "language": "python",
    "name": "QS_CustomerChurn_classifier_v2",
    "collapsed": false
   },
   "outputs": [],
   "source": "from snowflake.ml.registry import Registry\nfrom snowflake.ml.model import type_hints\n\nreg = Registry(session=session)\n\nMODEL_NAME = \"QS_CustomerChurn_classifier\"\nMODEL_VERSION = \"v2\"\n\nmv = reg.log_model(model,\n                   model_name=MODEL_NAME,\n                   version_name=MODEL_VERSION,\n                   options={'relax_version': True},\n                   task=type_hints.Task.TABULAR_BINARY_CLASSIFICATION)\nreg.show_models()\n",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "cdbf1034-3a65-4202-bb66-e5662ffa21bf",
   "metadata": {
    "name": "modelmonitor",
    "collapsed": false
   },
   "source": "\n## Crear un monitor para la nueva versión del modelo"
  },
  {
   "cell_type": "code",
   "id": "a6237f55-a907-4a97-ace3-d585bf0823c8",
   "metadata": {
    "language": "python",
    "name": "CHURN_MODEL_MONITOR_NEW",
    "collapsed": false
   },
   "outputs": [],
   "source": "query = f\"\"\"\nCREATE OR REPLACE MODEL MONITOR CHURN_MODEL_MONITOR_NEW\nWITH\n    MODEL=QS_CustomerChurn_classifier\n    VERSION=v2\n    FUNCTION=predict\n    SOURCE=CUSTOMERS_EVAL\n    BASELINE=CUSTOMERS_TRAINING\n    TIMESTAMP_COLUMN=TRANSACTIONTIMESTAMP\n    PREDICTION_CLASS_COLUMNS=(PREDICTED_CHURN)  \n    ACTUAL_CLASS_COLUMNS=(EXITED)\n    ID_COLUMNS=(CUSTOMERID)\n    WAREHOUSE=ML_WH\n    REFRESH_INTERVAL='1 min'\n    AGGREGATION_WINDOW='1 day';\n\"\"\"\nsession.sql(query).collect()",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "bf3a4231-7898-437e-ba01-534e407846d2",
   "metadata": {
    "name": "inference3",
    "collapsed": false
   },
   "source": "## Predecir el abandono con los nuevos datos de clientes utilizando el modelo reentrenado"
  },
  {
   "cell_type": "code",
   "id": "56381f7a-8ba7-4d84-9418-f0a974e4d747",
   "metadata": {
    "language": "python",
    "name": "inference_2",
    "collapsed": false
   },
   "outputs": [],
   "source": "status= inference('CUSTOMERS_EVAL','QS_CUSTOMERCHURN_CLASSIFIER', 'v2');",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "dbb3e3d2-e91b-4b72-822a-24bc81bb7986",
   "metadata": {
    "name": "MODEL_MONITOR_STAT_METRIC",
    "collapsed": false
   },
   "source": "### Recuperar los resúmenes estadísticos de una característica, etiqueta o predicción del modelo de un modelo monitorizado a lo largo del tiempo.\n🔹 Caso de Uso: Ayuda a analizar tendencias en el rendimiento del modelo, el comportamiento de las características y la distribución de las predicciones. El Nombre de la Métrica podría ser {'COUNT', 'COUNT_NULL'}\n### La granularidad puede ser de cualquier forma ‘<num> {DAY, WEEK, MONTH, QUARTER, YEAR}’, ALL o NULL"
  },
  {
   "cell_type": "code",
   "id": "2c7a1cf5-e8b0-4ef4-bf77-10ae24476830",
   "metadata": {
    "language": "sql",
    "name": "FEATURE_ML_MONITORING_METRICS_API",
    "collapsed": false
   },
   "outputs": [],
   "source": "\nSELECT * FROM \nTABLE(\nMODEL_MONITOR_STAT_METRIC(\n'CHURN_MODEL_MONITOR', 'COUNT', 'PREDICTED_CHURN', '1 DAY', TO_TIMESTAMP_TZ('2024-11-01'), TO_TIMESTAMP_TZ('2025-02-06'))\n) as a\nJOIN (SELECT * FROM \nTABLE(\nMODEL_MONITOR_STAT_METRIC(\n'CHURN_MODEL_MONITOR_NEW', 'COUNT', 'PREDICTED_CHURN', '1 DAY', TO_TIMESTAMP_TZ('2024-11-01'), TO_TIMESTAMP_TZ('2025-02-06'))\n)) as b ON a.EVENT_TIMESTAMP = b.EVENT_TIMESTAMP;\n",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "60655c57-1238-4097-9bcb-18e1bb18f098",
   "metadata": {
    "name": "MKMODEL_MONITOR_DRIFT_METRIC",
    "collapsed": false
   },
   "source": "### Calcular métricas de deriva para una característica, etiqueta o predicción del modelo especificada durante un período de tiempo dado.\nEsto ayuda a detectar cambios en las distribuciones de datos (deriva de características) o cambios en las predicciones (deriva de concepto)."
  },
  {
   "cell_type": "code",
   "id": "e61e700c-b3ef-4189-b849-6dfe04f9eeaa",
   "metadata": {
    "language": "sql",
    "name": "MODEL_MONITOR_DRIFT_METRIC",
    "collapsed": false
   },
   "outputs": [],
   "source": "\nSELECT * FROM TABLE(MODEL_MONITOR_DRIFT_METRIC(\n'CHURN_MODEL_MONITOR_NEW', 'DIFFERENCE_OF_MEANS', 'PREDICTED_CHURN', '1 DAY', TO_TIMESTAMP_TZ('2025-02-01'), TO_TIMESTAMP_TZ('2025-02-04')))",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "58592dd9-9fd0-40a8-bd5c-1e7c7bee1115",
   "metadata": {
    "name": "performance_metrics",
    "collapsed": false
   },
   "source": "### Propósito: Obtiene métricas de rendimiento para un modelo monitorizado en un rango de tiempo especificado.\n🔹 Caso de Uso: Permite realizar un seguimiento de cómo ha evolucionado el rendimiento del modelo (por ejemplo, caídas de precisión o degradación del rendimiento)."
  },
  {
   "cell_type": "code",
   "id": "0b8989d5-db2d-49c1-863b-7ea0d8f43fb0",
   "metadata": {
    "language": "sql",
    "name": "MODEL_MONITOR_PERFORMANCE_METRIC",
    "collapsed": false
   },
   "outputs": [],
   "source": "SELECT * FROM TABLE(MODEL_MONITOR_PERFORMANCE_METRIC(\n'CHURN_MODEL_MONITOR_NEW', 'PRECISION', '1 DAY', TO_TIMESTAMP_TZ('2024-11-01'), TO_TIMESTAMP_TZ('2025-02-05')))",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "27bb4ee0-07e5-4c11-aac8-bf7970e58451",
   "metadata": {
    "name": "setup_alert",
    "collapsed": false
   },
   "source": "### Configuración de Alertas"
  },
  {
   "cell_type": "markdown",
   "id": "ca6f26f8-ce8a-41f0-9998-f9748f776ff3",
   "metadata": {
    "name": "TEST_NOTIFICATION",
    "collapsed": false
   },
   "source": "Configurar Alertas para recibir notificaciones cuando una métrica determinada supera el límite de umbral."
  },
  {
   "cell_type": "code",
   "id": "87216d35-8600-41a8-bfff-efcf5e545e04",
   "metadata": {
    "language": "python",
    "name": "test_notification_table",
    "collapsed": false
   },
   "outputs": [],
   "source": "query=f'''CREATE or replace TABLE TEST_NOTIFICATION(\n    notification varchar (100),\n    created_at timestamp\n);'''\n\nsession.sql(query).collect()",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "f1bb686f-099a-43c6-8420-0b017501a904",
   "metadata": {
    "language": "sql",
    "name": "high_drift_alert",
    "collapsed": false
   },
   "outputs": [],
   "source": "CREATE OR REPLACE ALERT high_drift_alert\n    WAREHOUSE = ML_WH\n    SCHEDULE = '60 minutes'\n    IF ( EXISTS (SELECT * FROM TABLE(MODEL_MONITOR_DRIFT_METRIC(\n    'CHURN_MODEL_MONITOR', 'DIFFERENCE_OF_MEANS', 'PREDICTED_CHURN', '1 MONTH', TO_TIMESTAMP_TZ('2024-01-01'), TO_TIMESTAMP_TZ('2025-02-04')))))\n    THEN\n        INSERT INTO TEST_NOTIFICATION (notification, created_at) VALUES ('ALERT',(SELECT CURRENT_TIMESTAMP));",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "d89e2468-938a-4e17-bdb6-1706001133f2",
   "metadata": {
    "name": "end",
    "collapsed": false
   },
   "source": "## Fin del Notebook"
  }
 ]
}
